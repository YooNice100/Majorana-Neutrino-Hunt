{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87a8aae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NPML files: ['/Users/prithvikochhar/Documents/GitHub/Majorana-Neutrino-Hunt/data/MJD_NPML_0.hdf5', '/Users/prithvikochhar/Documents/GitHub/Majorana-Neutrino-Hunt/data/MJD_NPML_1.hdf5', '/Users/prithvikochhar/Documents/GitHub/Majorana-Neutrino-Hunt/data/MJD_NPML_2.hdf5']\n",
      "Processing /Users/prithvikochhar/Documents/GitHub/Majorana-Neutrino-Hunt/data/MJD_NPML_0.hdf5...\n",
      "  Found 65000 waveforms.\n",
      "    Processed 5000/65000 events...\n",
      "    Processed 10000/65000 events...\n",
      "    Processed 15000/65000 events...\n",
      "    Processed 20000/65000 events...\n",
      "    Processed 25000/65000 events...\n",
      "    Processed 30000/65000 events...\n",
      "    Processed 35000/65000 events...\n",
      "    Processed 40000/65000 events...\n",
      "    Processed 45000/65000 events...\n",
      "    Processed 50000/65000 events...\n",
      "    Processed 55000/65000 events...\n",
      "    Processed 60000/65000 events...\n",
      "    Processed 65000/65000 events...\n",
      "  Saved CSV to /Users/prithvikochhar/Documents/GitHub/Majorana-Neutrino-Hunt/data/params_npml/MJD_NPML_0_myparams.csv\n",
      "\n",
      "Processing /Users/prithvikochhar/Documents/GitHub/Majorana-Neutrino-Hunt/data/MJD_NPML_1.hdf5...\n",
      "  Found 65000 waveforms.\n",
      "    Processed 5000/65000 events...\n",
      "    Processed 10000/65000 events...\n",
      "    Processed 15000/65000 events...\n",
      "    Processed 20000/65000 events...\n",
      "    Processed 25000/65000 events...\n",
      "    Processed 30000/65000 events...\n",
      "    Processed 35000/65000 events...\n",
      "    Processed 40000/65000 events...\n",
      "    Processed 45000/65000 events...\n",
      "    Processed 50000/65000 events...\n",
      "    Processed 55000/65000 events...\n",
      "    Processed 60000/65000 events...\n",
      "    Processed 65000/65000 events...\n",
      "  Saved CSV to /Users/prithvikochhar/Documents/GitHub/Majorana-Neutrino-Hunt/data/params_npml/MJD_NPML_1_myparams.csv\n",
      "\n",
      "Processing /Users/prithvikochhar/Documents/GitHub/Majorana-Neutrino-Hunt/data/MJD_NPML_2.hdf5...\n",
      "  Found 29697 waveforms.\n",
      "    Processed 5000/29697 events...\n",
      "    Processed 10000/29697 events...\n",
      "    Processed 15000/29697 events...\n",
      "    Processed 20000/29697 events...\n",
      "    Processed 25000/29697 events...\n",
      "  Saved CSV to /Users/prithvikochhar/Documents/GitHub/Majorana-Neutrino-Hunt/data/params_npml/MJD_NPML_2_myparams.csv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "def compute_tdrift99_single(wf, tp0, frac=0.999):\n",
    "    n = len(wf)\n",
    "    start = int(tp0)\n",
    "    if start >= n - 1:\n",
    "        return np.nan\n",
    "    segment = wf[start:]\n",
    "    peak_val = segment.max()\n",
    "    if peak_val <= 0:\n",
    "        return np.nan\n",
    "    threshold = frac * peak_val\n",
    "    above = np.where(segment >= threshold)[0]\n",
    "    if len(above) == 0:\n",
    "        return np.nan\n",
    "    return float(above[0])\n",
    "def pole_zero_correct(wf, tau_samples=500.0):\n",
    "    alpha = np.exp(-1.0 / tau_samples)\n",
    "    y = np.zeros_like(wf, dtype=np.float64)\n",
    "    prev_x = wf[0]\n",
    "    prev_y = 0.0\n",
    "    for i in range(1, len(wf)):\n",
    "        x = float(wf[i])\n",
    "        y_i = x - prev_x + alpha * prev_y\n",
    "        y[i] = y_i\n",
    "        prev_x = x\n",
    "        prev_y = y_i\n",
    "    return y\n",
    "def compute_tfr_single(wf, tp0, tail_offset=200, tail_len=600):\n",
    "    n = len(wf)\n",
    "    start = int(tp0) + tail_offset\n",
    "    if start >= n - 10:\n",
    "        return np.nan\n",
    "    end = min(n, start + tail_len)\n",
    "    tail_raw = wf[start:end].astype(np.float64)\n",
    "    wf_pz = pole_zero_correct(wf)\n",
    "    tail_pz = wf_pz[start:end]\n",
    "    std_raw = np.std(tail_raw)\n",
    "    std_pz = np.std(tail_pz)\n",
    "    if std_pz <= 0:\n",
    "        return np.nan\n",
    "    return float(std_raw / std_pz)\n",
    "def smooth_gaussian(x, sigma=2.0):\n",
    "    if sigma <= 0:\n",
    "        return x.astype(np.float64)\n",
    "    radius = int(3 * sigma)\n",
    "    idx = np.arange(-radius, radius + 1, dtype=np.float64)\n",
    "    kernel = np.exp(-0.5 * (idx / sigma) ** 2)\n",
    "    kernel /= kernel.sum()\n",
    "    padded = np.pad(x, radius, mode=\"edge\")\n",
    "    conv = np.convolve(padded, kernel, mode=\"same\")\n",
    "    return conv[radius:-radius]\n",
    "def compute_peak_count_single(wf,tp0,window_after_tp0=400,grad_threshold_frac=0.05,min_separation=5):\n",
    "    n = len(wf)\n",
    "    tp0 = int(tp0)\n",
    "    base_end = min(200, n)\n",
    "    baseline = float(np.mean(wf[:base_end]))\n",
    "    wf_bs = wf - baseline\n",
    "    max_val = np.max(np.abs(wf_bs))\n",
    "    if max_val <= 0:\n",
    "        return 0\n",
    "    wf_norm = wf_bs / max_val\n",
    "    start = max(tp0 - 10, 0)\n",
    "    end = min(tp0 + window_after_tp0, n)\n",
    "    segment = wf_norm[start:end]\n",
    "    seg_smooth = smooth_gaussian(segment, sigma=2.0)\n",
    "    grad = np.gradient(seg_smooth)\n",
    "    gmax = np.max(np.abs(grad))\n",
    "    if gmax <= 0:\n",
    "        return 0\n",
    "    threshold = grad_threshold_frac * gmax\n",
    "    count = 0\n",
    "    last_peak_idx = -min_separation - 1\n",
    "    for i in range(1, len(grad) - 1):\n",
    "        if grad[i] > grad[i - 1] and grad[i] > grad[i + 1] and grad[i] >= threshold:\n",
    "            if i - last_peak_idx >= min_separation:\n",
    "                count += 1\n",
    "                last_peak_idx = i\n",
    "    return int(count)\n",
    "def compute_gradient_baseline_noise_single(wf, baseline_region=(0, 200)):\n",
    "    start, end = baseline_region\n",
    "    start = max(start, 0)\n",
    "    end = min(end, len(wf))\n",
    "    if end - start < 5:\n",
    "        return np.nan\n",
    "    segment = wf[start:end].astype(np.float64)\n",
    "    grad = np.gradient(segment)\n",
    "    return float(np.sqrt(np.mean(grad ** 2)))\n",
    "def compute_band_power_ratio_single(wf,fs=100e6,low_band=(0.1e6, 1e6),high_band=(1e6, 10e6),):\n",
    "    x = wf.astype(np.float64)\n",
    "    x = x - np.mean(x)\n",
    "    fft_vals = np.fft.rfft(x)\n",
    "    psd = np.abs(fft_vals) ** 2\n",
    "    freqs = np.fft.rfftfreq(len(x), d=1.0 / fs)\n",
    "    low_mask = (freqs >= low_band[0]) & (freqs < low_band[1])\n",
    "    high_mask = (freqs >= high_band[0]) & (freqs < high_band[1])\n",
    "    power_low = psd[low_mask].sum()\n",
    "    power_high = psd[high_mask].sum()\n",
    "    if power_low <= 0:\n",
    "        return np.nan\n",
    "    return float(power_high / power_low)\n",
    "def process_hdf5_file(h5_path, out_dir):\n",
    "    print(f\"Processing {h5_path}...\")\n",
    "    basename = os.path.basename(h5_path)\n",
    "    with h5py.File(h5_path, \"r\") as f:\n",
    "        waveforms = f[\"raw_waveform\"][:]         \n",
    "        tp0 = f[\"tp0\"][:]                        \n",
    "        ids = f[\"id\"][:]                        \n",
    "    n_events = waveforms.shape[0]\n",
    "    print(f\"  Found {n_events} waveforms.\")\n",
    "    tdrift10_list = []\n",
    "    tdrift50_list = []\n",
    "    tdrift_list = []\n",
    "    tfr_list = []\n",
    "    peak_count_list = []\n",
    "    gbn_list = []\n",
    "    bpr_list = []\n",
    "    for i in range(n_events):\n",
    "        wf = waveforms[i]\n",
    "        t0 = tp0[i]\n",
    "        tdrift10_list.append(compute_tdrift99_single(wf, t0, frac=0.10))\n",
    "        tdrift50_list.append(compute_tdrift99_single(wf, t0, frac=0.50))\n",
    "        tdrift_list.append(compute_tdrift99_single(wf, t0))\n",
    "        tfr_list.append(compute_tfr_single(wf, t0))\n",
    "        peak_count_list.append(compute_peak_count_single(wf, t0))\n",
    "        gbn_list.append(compute_gradient_baseline_noise_single(wf))\n",
    "        bpr_list.append(compute_band_power_ratio_single(wf))\n",
    "        if (i + 1) % 5000 == 0:\n",
    "            print(f\"    Processed {i + 1}/{n_events} events...\")\n",
    "    df = pd.DataFrame(\n",
    "        {\"id\": ids,\"file\": basename,\"tdrift10\": tdrift10_list,\"tdrift50\": tdrift50_list,\"tdrift99\": tdrift_list,\"tfr\": tfr_list,\n",
    "         \"peak_count\": peak_count_list,\"gbn\": gbn_list,\"bpr\": bpr_list,} )\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    out_name = os.path.splitext(basename)[0] + \"_myparams.csv\"\n",
    "    out_path = os.path.join(out_dir, out_name)\n",
    "    df.to_csv(out_path, index=False)\n",
    "    print(f\"  Saved CSV to {out_path}\\n\")\n",
    "def main():\n",
    "    DATA_DIR = os.path.abspath(\"../../data\")\n",
    "    NPML_PATTERN = os.path.join(DATA_DIR, \"MJD_NPML*.hdf5\")\n",
    "    OUT_DIR_NPML = os.path.join(DATA_DIR, \"params_npml\")\n",
    "    npml_files = sorted(glob.glob(NPML_PATTERN))\n",
    "    print(\"NPML files:\", npml_files)\n",
    "    for path in npml_files:\n",
    "        process_hdf5_file(path, OUT_DIR_NPML)\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b3a792e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "file_list = [\"/Users/prithvikochhar/Documents/GitHub/Majorana-Neutrino-Hunt/data/params_npml/MJD_NPML_0_myparams.csv\",\n",
    "             \"/Users/prithvikochhar/Documents/GitHub/Majorana-Neutrino-Hunt/data/params_npml/MJD_NPML_1_myparams.csv\",\n",
    "             \"/Users/prithvikochhar/Documents/GitHub/Majorana-Neutrino-Hunt/data/params_npml/MJD_NPML_2_myparams.csv\"]\n",
    "df_list = []\n",
    "for file in file_list:\n",
    "    df = pd.read_csv(file)\n",
    "    df_list.append(df)\n",
    "combined_df = pd.concat(df_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c69200b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = \"prithvi_combined_npml.csv.gz\"\n",
    "combined_df.to_csv(\n",
    "    output_file,\n",
    "    index=False,\n",
    "    compression=\"gzip\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c6616e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
