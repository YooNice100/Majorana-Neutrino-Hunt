{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48d978c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: ED_train_all.csv (1040000, 2)\n",
      "Merging: HWP_train_all.csv (1040000, 2)\n",
      "Merging: LQ80_train_all.csv (1040000, 2)\n",
      "Merging: PPR_train_all.csv (1040000, 2)\n",
      "Merging: SCA_train_all.csv (1040000, 2)\n",
      "Merging: ND80_train_all.csv (1040000, 2)\n",
      "\n",
      "Final merged TRAIN shape: (1040000, 7)\n",
      "          id      ED     HWP           LQ80       PPR       SCA  ND80\n",
      "0  0_train_0  3409.0  2120.0 -635333.796311  0.699672  0.034655   0.0\n",
      "1  1_train_0  3404.0  2004.0 -289756.893085  0.687174  0.035314   0.0\n",
      "2  2_train_0  3411.0  2125.0 -379843.029134  0.700985  0.034915   0.0\n",
      "3  3_train_0  3408.0  2098.0 -252673.626844  0.697850  0.034752   0.0\n",
      "4  4_train_0  3406.0  2037.0 -317761.453582  0.690585  0.035132   0.0\n",
      "\n",
      "Saved gzipped TRAIN CSV to:\n",
      "c:\\Users\\YooNi\\OneDrive\\Desktop\\Majorana-Neutrino-Hunt\\notebooks\\finalcsveunice\\train_all_features.csv.gz\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "FEATURE_DIR = \".\"  # set to \"finalcsveunice\" if running from repo root\n",
    "\n",
    "train_feature_files = [\n",
    "    \"ED_train_all.csv\",\n",
    "    \"HWP_train_all.csv\",\n",
    "    \"LQ80_train_all.csv\",\n",
    "    \"PPR_train_all.csv\",\n",
    "    \"SCA_train_all.csv\",\n",
    "    \"ND80_train_all.csv\"\n",
    "]\n",
    "\n",
    "# Load first file\n",
    "df_train = pd.read_csv(os.path.join(FEATURE_DIR, train_feature_files[0]))\n",
    "print(\"Loaded:\", train_feature_files[0], df_train.shape)\n",
    "\n",
    "# Merge remaining\n",
    "for fname in train_feature_files[1:]:\n",
    "    path = os.path.join(FEATURE_DIR, fname)\n",
    "    temp = pd.read_csv(path)\n",
    "    print(\"Merging:\", fname, temp.shape)\n",
    "    df_train = df_train.merge(temp, on=\"id\", how=\"inner\")\n",
    "\n",
    "print(\"\\nFinal merged TRAIN shape:\", df_train.shape)\n",
    "print(df_train.head())\n",
    "\n",
    "# Save gzipped\n",
    "train_out = os.path.join(FEATURE_DIR, \"train_all_features.csv.gz\")\n",
    "df_train.to_csv(train_out, index=False, compression=\"gzip\")\n",
    "\n",
    "print(\"\\nSaved gzipped TRAIN CSV to:\")\n",
    "print(os.path.abspath(train_out))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "644bb143",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\YooNi\\OneDrive\\Desktop\\Majorana-Neutrino-Hunt\\notebooks\\finalcsveunice\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ab8cf07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: ED_test_all.csv (390000, 2)\n",
      "Merging: HWP_test_all.csv (390000, 2)\n",
      "Merging: LQ80_test_all.csv (390000, 2)\n",
      "Merging: PPR_test_all.csv (390000, 2)\n",
      "Merging: SCA_test_all.csv (390000, 2)\n",
      "Merging: ND80_test_all.csv (390000, 2)\n",
      "\n",
      "Final merged TEST shape: (390000, 7)\n",
      "               id      ED     HWP          LQ80       PPR       SCA  ND80\n",
      "0  2395098_test_0  3407.0  2036.0 -1.300536e+06  0.692435  0.034359   0.0\n",
      "1  2395099_test_0  3405.0  2019.0 -9.729822e+05  0.690517  0.034267   0.0\n",
      "2  2395100_test_0  3412.0  2107.0 -6.390870e+05  0.700524  0.034659   0.0\n",
      "3  2395101_test_0  3408.0  2053.0 -2.760460e+05  0.690450  0.034947   0.0\n",
      "4  2395102_test_0  3406.0  1939.0 -7.611188e+04  0.677887  0.040895   0.0\n",
      "\n",
      "Saved gzipped TEST CSV to:\n",
      "c:\\Users\\YooNi\\OneDrive\\Desktop\\Majorana-Neutrino-Hunt\\notebooks\\finalcsveunice\\test_all_features.csv.gz\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "FEATURE_DIR = \".\"  # set to \"finalcsveunice\" if running from repo root\n",
    "\n",
    "test_feature_files = [\n",
    "    \"ED_test_all.csv\",\n",
    "    \"HWP_test_all.csv\",\n",
    "    \"LQ80_test_all.csv\",\n",
    "    \"PPR_test_all.csv\",\n",
    "    \"SCA_test_all.csv\",\n",
    "    \"ND80_test_all.csv\"\n",
    "]\n",
    "\n",
    "# Load first file\n",
    "df_test = pd.read_csv(os.path.join(FEATURE_DIR, test_feature_files[0]))\n",
    "print(\"Loaded:\", test_feature_files[0], df_test.shape)\n",
    "\n",
    "# Merge remaining\n",
    "for fname in test_feature_files[1:]:\n",
    "    path = os.path.join(FEATURE_DIR, fname)\n",
    "    temp = pd.read_csv(path)\n",
    "    print(\"Merging:\", fname, temp.shape)\n",
    "    df_test = df_test.merge(temp, on=\"id\", how=\"inner\")\n",
    "\n",
    "print(\"\\nFinal merged TEST shape:\", df_test.shape)\n",
    "print(df_test.head())\n",
    "\n",
    "# Save gzipped\n",
    "test_out = os.path.join(FEATURE_DIR, \"test_all_features.csv.gz\")\n",
    "df_test.to_csv(test_out, index=False, compression=\"gzip\")\n",
    "\n",
    "print(\"\\nSaved gzipped TEST CSV to:\")\n",
    "print(os.path.abspath(test_out))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01b9167",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c5ad614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MISSING VALUE CHECK\n",
      "\n",
      "TRAIN dataset\n",
      "Total missing values: 0\n",
      "\n",
      "Missing values per column (TRAIN):\n",
      "Series([], dtype: int64)\n",
      "\n",
      "TRAIN: no missing values\n",
      "\n",
      "TEST dataset\n",
      "Total missing values: 0\n",
      "\n",
      "Missing values per column (TEST):\n",
      "Series([], dtype: int64)\n",
      "\n",
      "TEST: no missing values\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nMISSING VALUE CHECK\")\n",
    "\n",
    "# ---- TRAIN ----\n",
    "print(\"\\nTRAIN dataset\")\n",
    "total_missing_train = df_train.isna().sum().sum()\n",
    "print(\"Total missing values:\", total_missing_train)\n",
    "\n",
    "missing_by_col_train = df_train.isna().sum()\n",
    "print(\"\\nMissing values per column (TRAIN):\")\n",
    "print(missing_by_col_train[missing_by_col_train > 0])\n",
    "\n",
    "if total_missing_train == 0:\n",
    "    print(\"\\nTRAIN: no missing values\")\n",
    "else:\n",
    "    print(\"\\nTRAIN: missing values detected\")\n",
    "\n",
    "# ---- TEST ----\n",
    "print(\"\\nTEST dataset\")\n",
    "total_missing_test = df_test.isna().sum().sum()\n",
    "print(\"Total missing values:\", total_missing_test)\n",
    "\n",
    "missing_by_col_test = df_test.isna().sum()\n",
    "print(\"\\nMissing values per column (TEST):\")\n",
    "print(missing_by_col_test[missing_by_col_test > 0])\n",
    "\n",
    "if total_missing_test == 0:\n",
    "    print(\"\\nTEST: no missing values\")\n",
    "else:\n",
    "    print(\"\\nTEST: missing values detected\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb572a5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
