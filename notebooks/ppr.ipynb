{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1c8c3b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added to Python path: c:\\Users\\YooNi\\OneDrive\\Desktop\\Majorana-Neutrino-Hunt\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "# Get the project root (one level above notebooks/)\n",
    "project_root = os.path.abspath(\"..\")\n",
    "sys.path.append(project_root)\n",
    "\n",
    "print(\"Added to Python path:\", project_root)\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# from src.parameters.tail_features import compute_LQ80\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79ebbf6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_file = \"../data/old/MJD_Train_0.hdf5\"\n",
    "\n",
    "# with h5py.File(train_file, \"r\") as f:\n",
    "#     waveforms = np.array(f[\"raw_waveform\"])\n",
    "#     ids = np.array(f[\"id\"])\n",
    "\n",
    "# print(\"Loaded\", len(waveforms), \"waveforms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb25e842",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_PPR(waveform, n_plateau=300):\n",
    "    \"\"\"\n",
    "    Peak Plateau Ratio (PPR)\n",
    "\n",
    "    Measures how much the waveform \"flattens\" toward the end of the trace.\n",
    "    Defined as:\n",
    "\n",
    "        PPR = (mean of last n_plateau samples) / (peak height)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    waveform : array-like\n",
    "        The raw waveform.\n",
    "    n_plateau : int\n",
    "        Number of samples to use at the end for averaging the plateau.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The Peak Plateau Ratio. NaN if peak is zero.\n",
    "    \"\"\"\n",
    "    y = np.asarray(waveform, dtype=float)\n",
    "\n",
    "    peak_val = float(np.max(y))\n",
    "    if peak_val <= 0:\n",
    "        return np.nan  # avoid division by zero or negative peak\n",
    "\n",
    "    # Average of last N samples (plateau region)\n",
    "    plateau = float(np.mean(y[-n_plateau:]))\n",
    "\n",
    "    return plateau / peak_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "baef5f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # compute PPR for everything\n",
    "# PPR_values = []\n",
    "\n",
    "# # for i, wf in enumerate(waveforms):\n",
    "# #     val = compute_PPR(wf)\n",
    "# #     PPR_values.append(val)\n",
    "# for i, wf in enumerate(waveforms):\n",
    "#     if i % 5000 == 0:\n",
    "#         print(f\"Processing {i} / {len(waveforms)}\")\n",
    "#     PPR_values.append(compute_PPR(wf))\n",
    "\n",
    "\n",
    "# PPR_values = np.array(PPR_values, dtype=float)\n",
    "# PPR_values[~np.isfinite(PPR_values)] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4bb1eaaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # output\n",
    "# formatted_ids = [f\"{id_}_train_0\" for id_ in ids]\n",
    "\n",
    "# df = pd.DataFrame({\n",
    "#     \"id\": formatted_ids,\n",
    "#     \"PPR\": PPR_values\n",
    "# })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9690001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_path = \"PPR_train_0.csv\"\n",
    "# df.to_csv(output_path, index=False)\n",
    "# print(\"Saved to\", output_path)\n",
    "# print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1a81858",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df[\"PPR\"].describe())\n",
    "# print(\"NaNs:\", df[\"PPR\"].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f50a51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4da191c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "\n",
    "# vals = df[\"PPR\"].to_numpy(dtype=float)\n",
    "# vals = vals[np.isfinite(vals)]\n",
    "\n",
    "# plt.figure()\n",
    "# plt.hist(vals, bins=200)\n",
    "# plt.yscale(\"log\")\n",
    "# plt.xlabel(\"PPR\")\n",
    "# plt.ylabel(\"Count\")\n",
    "# plt.title(\"PPR Distribution (Train 0)\")\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "422bdcb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIR = \"finalcsveunice\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "605c9b5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Train_0: 65000 waveforms\n",
      "  Train_0 processing 0/65000\n",
      "  Train_0 processing 5000/65000\n",
      "  Train_0 processing 10000/65000\n",
      "  Train_0 processing 15000/65000\n",
      "  Train_0 processing 20000/65000\n",
      "  Train_0 processing 25000/65000\n",
      "  Train_0 processing 30000/65000\n",
      "  Train_0 processing 35000/65000\n",
      "  Train_0 processing 40000/65000\n",
      "  Train_0 processing 45000/65000\n",
      "  Train_0 processing 50000/65000\n",
      "  Train_0 processing 55000/65000\n",
      "  Train_0 processing 60000/65000\n",
      "Loaded Train_1: 65000 waveforms\n",
      "  Train_1 processing 0/65000\n",
      "  Train_1 processing 5000/65000\n",
      "  Train_1 processing 10000/65000\n",
      "  Train_1 processing 15000/65000\n",
      "  Train_1 processing 20000/65000\n",
      "  Train_1 processing 25000/65000\n",
      "  Train_1 processing 30000/65000\n",
      "  Train_1 processing 35000/65000\n",
      "  Train_1 processing 40000/65000\n",
      "  Train_1 processing 45000/65000\n",
      "  Train_1 processing 50000/65000\n",
      "  Train_1 processing 55000/65000\n",
      "  Train_1 processing 60000/65000\n",
      "Loaded Train_2: 65000 waveforms\n",
      "  Train_2 processing 0/65000\n",
      "  Train_2 processing 5000/65000\n",
      "  Train_2 processing 10000/65000\n",
      "  Train_2 processing 15000/65000\n",
      "  Train_2 processing 20000/65000\n",
      "  Train_2 processing 25000/65000\n",
      "  Train_2 processing 30000/65000\n",
      "  Train_2 processing 35000/65000\n",
      "  Train_2 processing 40000/65000\n",
      "  Train_2 processing 45000/65000\n",
      "  Train_2 processing 50000/65000\n",
      "  Train_2 processing 55000/65000\n",
      "  Train_2 processing 60000/65000\n",
      "Loaded Train_3: 65000 waveforms\n",
      "  Train_3 processing 0/65000\n",
      "  Train_3 processing 5000/65000\n",
      "  Train_3 processing 10000/65000\n",
      "  Train_3 processing 15000/65000\n",
      "  Train_3 processing 20000/65000\n",
      "  Train_3 processing 25000/65000\n",
      "  Train_3 processing 30000/65000\n",
      "  Train_3 processing 35000/65000\n",
      "  Train_3 processing 40000/65000\n",
      "  Train_3 processing 45000/65000\n",
      "  Train_3 processing 50000/65000\n",
      "  Train_3 processing 55000/65000\n",
      "  Train_3 processing 60000/65000\n",
      "Loaded Train_4: 65000 waveforms\n",
      "  Train_4 processing 0/65000\n",
      "  Train_4 processing 5000/65000\n",
      "  Train_4 processing 10000/65000\n",
      "  Train_4 processing 15000/65000\n",
      "  Train_4 processing 20000/65000\n",
      "  Train_4 processing 25000/65000\n",
      "  Train_4 processing 30000/65000\n",
      "  Train_4 processing 35000/65000\n",
      "  Train_4 processing 40000/65000\n",
      "  Train_4 processing 45000/65000\n",
      "  Train_4 processing 50000/65000\n",
      "  Train_4 processing 55000/65000\n",
      "  Train_4 processing 60000/65000\n",
      "Loaded Train_5: 65000 waveforms\n",
      "  Train_5 processing 0/65000\n",
      "  Train_5 processing 5000/65000\n",
      "  Train_5 processing 10000/65000\n",
      "  Train_5 processing 15000/65000\n",
      "  Train_5 processing 20000/65000\n",
      "  Train_5 processing 25000/65000\n",
      "  Train_5 processing 30000/65000\n",
      "  Train_5 processing 35000/65000\n",
      "  Train_5 processing 40000/65000\n",
      "  Train_5 processing 45000/65000\n",
      "  Train_5 processing 50000/65000\n",
      "  Train_5 processing 55000/65000\n",
      "  Train_5 processing 60000/65000\n",
      "Loaded Train_6: 65000 waveforms\n",
      "  Train_6 processing 0/65000\n",
      "  Train_6 processing 5000/65000\n",
      "  Train_6 processing 10000/65000\n",
      "  Train_6 processing 15000/65000\n",
      "  Train_6 processing 20000/65000\n",
      "  Train_6 processing 25000/65000\n",
      "  Train_6 processing 30000/65000\n",
      "  Train_6 processing 35000/65000\n",
      "  Train_6 processing 40000/65000\n",
      "  Train_6 processing 45000/65000\n",
      "  Train_6 processing 50000/65000\n",
      "  Train_6 processing 55000/65000\n",
      "  Train_6 processing 60000/65000\n",
      "Loaded Train_7: 65000 waveforms\n",
      "  Train_7 processing 0/65000\n",
      "  Train_7 processing 5000/65000\n",
      "  Train_7 processing 10000/65000\n",
      "  Train_7 processing 15000/65000\n",
      "  Train_7 processing 20000/65000\n",
      "  Train_7 processing 25000/65000\n",
      "  Train_7 processing 30000/65000\n",
      "  Train_7 processing 35000/65000\n",
      "  Train_7 processing 40000/65000\n",
      "  Train_7 processing 45000/65000\n",
      "  Train_7 processing 50000/65000\n",
      "  Train_7 processing 55000/65000\n",
      "  Train_7 processing 60000/65000\n",
      "Loaded Train_8: 65000 waveforms\n",
      "  Train_8 processing 0/65000\n",
      "  Train_8 processing 5000/65000\n",
      "  Train_8 processing 10000/65000\n",
      "  Train_8 processing 15000/65000\n",
      "  Train_8 processing 20000/65000\n",
      "  Train_8 processing 25000/65000\n",
      "  Train_8 processing 30000/65000\n",
      "  Train_8 processing 35000/65000\n",
      "  Train_8 processing 40000/65000\n",
      "  Train_8 processing 45000/65000\n",
      "  Train_8 processing 50000/65000\n",
      "  Train_8 processing 55000/65000\n",
      "  Train_8 processing 60000/65000\n",
      "Loaded Train_9: 65000 waveforms\n",
      "  Train_9 processing 0/65000\n",
      "  Train_9 processing 5000/65000\n",
      "  Train_9 processing 10000/65000\n",
      "  Train_9 processing 15000/65000\n",
      "  Train_9 processing 20000/65000\n",
      "  Train_9 processing 25000/65000\n",
      "  Train_9 processing 30000/65000\n",
      "  Train_9 processing 35000/65000\n",
      "  Train_9 processing 40000/65000\n",
      "  Train_9 processing 45000/65000\n",
      "  Train_9 processing 50000/65000\n",
      "  Train_9 processing 55000/65000\n",
      "  Train_9 processing 60000/65000\n",
      "Loaded Train_10: 65000 waveforms\n",
      "  Train_10 processing 0/65000\n",
      "  Train_10 processing 5000/65000\n",
      "  Train_10 processing 10000/65000\n",
      "  Train_10 processing 15000/65000\n",
      "  Train_10 processing 20000/65000\n",
      "  Train_10 processing 25000/65000\n",
      "  Train_10 processing 30000/65000\n",
      "  Train_10 processing 35000/65000\n",
      "  Train_10 processing 40000/65000\n",
      "  Train_10 processing 45000/65000\n",
      "  Train_10 processing 50000/65000\n",
      "  Train_10 processing 55000/65000\n",
      "  Train_10 processing 60000/65000\n",
      "Loaded Train_11: 65000 waveforms\n",
      "  Train_11 processing 0/65000\n",
      "  Train_11 processing 5000/65000\n",
      "  Train_11 processing 10000/65000\n",
      "  Train_11 processing 15000/65000\n",
      "  Train_11 processing 20000/65000\n",
      "  Train_11 processing 25000/65000\n",
      "  Train_11 processing 30000/65000\n",
      "  Train_11 processing 35000/65000\n",
      "  Train_11 processing 40000/65000\n",
      "  Train_11 processing 45000/65000\n",
      "  Train_11 processing 50000/65000\n",
      "  Train_11 processing 55000/65000\n",
      "  Train_11 processing 60000/65000\n",
      "Loaded Train_12: 65000 waveforms\n",
      "  Train_12 processing 0/65000\n",
      "  Train_12 processing 5000/65000\n",
      "  Train_12 processing 10000/65000\n",
      "  Train_12 processing 15000/65000\n",
      "  Train_12 processing 20000/65000\n",
      "  Train_12 processing 25000/65000\n",
      "  Train_12 processing 30000/65000\n",
      "  Train_12 processing 35000/65000\n",
      "  Train_12 processing 40000/65000\n",
      "  Train_12 processing 45000/65000\n",
      "  Train_12 processing 50000/65000\n",
      "  Train_12 processing 55000/65000\n",
      "  Train_12 processing 60000/65000\n",
      "Loaded Train_13: 65000 waveforms\n",
      "  Train_13 processing 0/65000\n",
      "  Train_13 processing 5000/65000\n",
      "  Train_13 processing 10000/65000\n",
      "  Train_13 processing 15000/65000\n",
      "  Train_13 processing 20000/65000\n",
      "  Train_13 processing 25000/65000\n",
      "  Train_13 processing 30000/65000\n",
      "  Train_13 processing 35000/65000\n",
      "  Train_13 processing 40000/65000\n",
      "  Train_13 processing 45000/65000\n",
      "  Train_13 processing 50000/65000\n",
      "  Train_13 processing 55000/65000\n",
      "  Train_13 processing 60000/65000\n",
      "Loaded Train_14: 65000 waveforms\n",
      "  Train_14 processing 0/65000\n",
      "  Train_14 processing 5000/65000\n",
      "  Train_14 processing 10000/65000\n",
      "  Train_14 processing 15000/65000\n",
      "  Train_14 processing 20000/65000\n",
      "  Train_14 processing 25000/65000\n",
      "  Train_14 processing 30000/65000\n",
      "  Train_14 processing 35000/65000\n",
      "  Train_14 processing 40000/65000\n",
      "  Train_14 processing 45000/65000\n",
      "  Train_14 processing 50000/65000\n",
      "  Train_14 processing 55000/65000\n",
      "  Train_14 processing 60000/65000\n",
      "Loaded Train_15: 65000 waveforms\n",
      "  Train_15 processing 0/65000\n",
      "  Train_15 processing 5000/65000\n",
      "  Train_15 processing 10000/65000\n",
      "  Train_15 processing 15000/65000\n",
      "  Train_15 processing 20000/65000\n",
      "  Train_15 processing 25000/65000\n",
      "  Train_15 processing 30000/65000\n",
      "  Train_15 processing 35000/65000\n",
      "  Train_15 processing 40000/65000\n",
      "  Train_15 processing 45000/65000\n",
      "  Train_15 processing 50000/65000\n",
      "  Train_15 processing 55000/65000\n",
      "  Train_15 processing 60000/65000\n",
      "\n",
      "Saved combined PPR CSV to: finalcsveunice\\PPR_train_all.csv\n",
      "          id       PPR\n",
      "0  0_train_0  0.719376\n",
      "1  1_train_0  0.729709\n",
      "2  2_train_0  0.715390\n",
      "3  3_train_0  0.769375\n",
      "4  4_train_0  0.728165\n",
      "count    1.039995e+06\n",
      "mean     7.254552e-01\n",
      "std      2.832694e-02\n",
      "min     -7.703542e+00\n",
      "25%      7.088948e-01\n",
      "50%      7.211736e-01\n",
      "75%      7.361495e-01\n",
      "max      9.768917e-01\n",
      "Name: PPR, dtype: float64\n",
      "NaNs: 5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "all_ids = []\n",
    "all_PPR = []\n",
    "\n",
    "for train_idx in range(16):\n",
    "    train_file = f\"../data/old/MJD_Train_{train_idx}.hdf5\"\n",
    "    if not os.path.exists(train_file):\n",
    "        print(f\"Skipping missing file: {train_file}\")\n",
    "        continue\n",
    "\n",
    "    with h5py.File(train_file, \"r\") as f:\n",
    "        waveforms = np.array(f[\"raw_waveform\"])\n",
    "        ids = np.array(f[\"id\"])\n",
    "\n",
    "    print(f\"Loaded Train_{train_idx}: {len(waveforms)} waveforms\")\n",
    "\n",
    "    for i, wf in enumerate(waveforms):\n",
    "        if i % 5000 == 0:\n",
    "            print(f\"  Train_{train_idx} processing {i}/{len(waveforms)}\")\n",
    "\n",
    "        all_PPR.append(compute_PPR(wf))\n",
    "        all_ids.append(f\"{ids[i]}_train_{train_idx}\")\n",
    "\n",
    "all_PPR = np.array(all_PPR, dtype=float)\n",
    "all_PPR[~np.isfinite(all_PPR)] = np.nan\n",
    "\n",
    "df_ppr = pd.DataFrame({\n",
    "    \"id\": all_ids,\n",
    "    \"PPR\": all_PPR\n",
    "})\n",
    "\n",
    "output_path_ppr = os.path.join(OUTPUT_DIR, \"PPR_train_all.csv\")\n",
    "df_ppr.to_csv(output_path_ppr, index=False)\n",
    "\n",
    "print(\"\\nSaved combined PPR CSV to:\", output_path_ppr)\n",
    "print(df_ppr.head())\n",
    "print(df_ppr[\"PPR\"].describe())\n",
    "print(\"NaNs:\", df_ppr[\"PPR\"].isna().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12130858",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f8605d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "35980acf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Test_0: 65000 waveforms\n",
      "  Test_0 processing 0/65000\n",
      "  Test_0 processing 5000/65000\n",
      "  Test_0 processing 10000/65000\n",
      "  Test_0 processing 15000/65000\n",
      "  Test_0 processing 20000/65000\n",
      "  Test_0 processing 25000/65000\n",
      "  Test_0 processing 30000/65000\n",
      "  Test_0 processing 35000/65000\n",
      "  Test_0 processing 40000/65000\n",
      "  Test_0 processing 45000/65000\n",
      "  Test_0 processing 50000/65000\n",
      "  Test_0 processing 55000/65000\n",
      "  Test_0 processing 60000/65000\n",
      "Loaded Test_1: 65000 waveforms\n",
      "  Test_1 processing 0/65000\n",
      "  Test_1 processing 5000/65000\n",
      "  Test_1 processing 10000/65000\n",
      "  Test_1 processing 15000/65000\n",
      "  Test_1 processing 20000/65000\n",
      "  Test_1 processing 25000/65000\n",
      "  Test_1 processing 30000/65000\n",
      "  Test_1 processing 35000/65000\n",
      "  Test_1 processing 40000/65000\n",
      "  Test_1 processing 45000/65000\n",
      "  Test_1 processing 50000/65000\n",
      "  Test_1 processing 55000/65000\n",
      "  Test_1 processing 60000/65000\n",
      "Loaded Test_2: 65000 waveforms\n",
      "  Test_2 processing 0/65000\n",
      "  Test_2 processing 5000/65000\n",
      "  Test_2 processing 10000/65000\n",
      "  Test_2 processing 15000/65000\n",
      "  Test_2 processing 20000/65000\n",
      "  Test_2 processing 25000/65000\n",
      "  Test_2 processing 30000/65000\n",
      "  Test_2 processing 35000/65000\n",
      "  Test_2 processing 40000/65000\n",
      "  Test_2 processing 45000/65000\n",
      "  Test_2 processing 50000/65000\n",
      "  Test_2 processing 55000/65000\n",
      "  Test_2 processing 60000/65000\n",
      "Loaded Test_3: 65000 waveforms\n",
      "  Test_3 processing 0/65000\n",
      "  Test_3 processing 5000/65000\n",
      "  Test_3 processing 10000/65000\n",
      "  Test_3 processing 15000/65000\n",
      "  Test_3 processing 20000/65000\n",
      "  Test_3 processing 25000/65000\n",
      "  Test_3 processing 30000/65000\n",
      "  Test_3 processing 35000/65000\n",
      "  Test_3 processing 40000/65000\n",
      "  Test_3 processing 45000/65000\n",
      "  Test_3 processing 50000/65000\n",
      "  Test_3 processing 55000/65000\n",
      "  Test_3 processing 60000/65000\n",
      "Loaded Test_4: 65000 waveforms\n",
      "  Test_4 processing 0/65000\n",
      "  Test_4 processing 5000/65000\n",
      "  Test_4 processing 10000/65000\n",
      "  Test_4 processing 15000/65000\n",
      "  Test_4 processing 20000/65000\n",
      "  Test_4 processing 25000/65000\n",
      "  Test_4 processing 30000/65000\n",
      "  Test_4 processing 35000/65000\n",
      "  Test_4 processing 40000/65000\n",
      "  Test_4 processing 45000/65000\n",
      "  Test_4 processing 50000/65000\n",
      "  Test_4 processing 55000/65000\n",
      "  Test_4 processing 60000/65000\n",
      "Loaded Test_5: 65000 waveforms\n",
      "  Test_5 processing 0/65000\n",
      "  Test_5 processing 5000/65000\n",
      "  Test_5 processing 10000/65000\n",
      "  Test_5 processing 15000/65000\n",
      "  Test_5 processing 20000/65000\n",
      "  Test_5 processing 25000/65000\n",
      "  Test_5 processing 30000/65000\n",
      "  Test_5 processing 35000/65000\n",
      "  Test_5 processing 40000/65000\n",
      "  Test_5 processing 45000/65000\n",
      "  Test_5 processing 50000/65000\n",
      "  Test_5 processing 55000/65000\n",
      "  Test_5 processing 60000/65000\n",
      "\n",
      "Saved combined PPR TEST CSV to: finalcsveunice\\PPR_test_all.csv\n",
      "               id       PPR\n",
      "0  2395098_test_0  0.703203\n",
      "1  2395099_test_0  0.704814\n",
      "2  2395100_test_0  0.720109\n",
      "3  2395101_test_0  0.714324\n",
      "4  2395102_test_0  0.747169\n",
      "count    390000.000000\n",
      "mean          0.725407\n",
      "std           0.026828\n",
      "min           0.002385\n",
      "25%           0.708899\n",
      "50%           0.721178\n",
      "75%           0.736180\n",
      "max           0.987180\n",
      "Name: PPR, dtype: float64\n",
      "NaNs: 0\n"
     ]
    }
   ],
   "source": [
    "# PPR test\n",
    "all_test_ids_ppr = []\n",
    "all_PPR_test = []\n",
    "\n",
    "for test_idx in range(6):\n",
    "    test_file = f\"../data/old/MJD_Test_{test_idx}.hdf5\"\n",
    "    if not os.path.exists(test_file):\n",
    "        print(f\"Skipping missing file: {test_file}\")\n",
    "        continue\n",
    "\n",
    "    with h5py.File(test_file, \"r\") as f:\n",
    "        waveforms_test = np.array(f[\"raw_waveform\"])\n",
    "        ids_test = np.array(f[\"id\"])\n",
    "\n",
    "    print(f\"Loaded Test_{test_idx}: {len(waveforms_test)} waveforms\")\n",
    "\n",
    "    for i, wf in enumerate(waveforms_test):\n",
    "        if i % 5000 == 0:\n",
    "            print(f\"  Test_{test_idx} processing {i}/{len(waveforms_test)}\")\n",
    "\n",
    "        all_PPR_test.append(compute_PPR(wf))\n",
    "        all_test_ids_ppr.append(f\"{ids_test[i]}_test_{test_idx}\")\n",
    "\n",
    "all_PPR_test = np.array(all_PPR_test, dtype=float)\n",
    "all_PPR_test[~np.isfinite(all_PPR_test)] = np.nan\n",
    "\n",
    "df_ppr_test = pd.DataFrame({\n",
    "    \"id\": all_test_ids_ppr,\n",
    "    \"PPR\": all_PPR_test\n",
    "})\n",
    "\n",
    "output_path_ppr_test = os.path.join(OUTPUT_DIR, \"PPR_test_all.csv\")\n",
    "df_ppr_test.to_csv(output_path_ppr_test, index=False)\n",
    "\n",
    "print(\"\\nSaved combined PPR TEST CSV to:\", output_path_ppr_test)\n",
    "print(df_ppr_test.head())\n",
    "print(df_ppr_test[\"PPR\"].describe())\n",
    "print(\"NaNs:\", df_ppr_test[\"PPR\"].isna().sum())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
