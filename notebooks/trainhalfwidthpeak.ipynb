{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "495939fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added to Python path: c:\\Users\\YooNi\\OneDrive\\Desktop\\Majorana-Neutrino-Hunt\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Get the project root (one level above notebooks/)\n",
    "project_root = os.path.abspath(\"..\")\n",
    "sys.path.append(project_root)\n",
    "\n",
    "print(\"Added to Python path:\", project_root)\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# from src.parameters.tail_features import compute_LQ80\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f504d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_HWP(waveform):\n",
    "    y = np.asarray(waveform, dtype=float)\n",
    "\n",
    "    peak_val = float(np.max(y))\n",
    "    if peak_val <= 0:\n",
    "        return np.nan\n",
    "\n",
    "    level25 = 0.25 * peak_val\n",
    "    level75 = 0.75 * peak_val\n",
    "\n",
    "    above_25 = np.where(y >= level25)[0]\n",
    "    above_75 = np.where(y >= level75)[0]\n",
    "\n",
    "    if len(above_25) == 0 or len(above_75) == 0:\n",
    "        return np.nan\n",
    "\n",
    "    left_idx = int(above_25[0])\n",
    "    right_idx = int(above_75[-1])\n",
    "\n",
    "    width = right_idx - left_idx\n",
    "    if width < 0:\n",
    "        return np.nan\n",
    "\n",
    "    return float(width)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9aade5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c4c8e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIR = \"finalcsveunice\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3172d8a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Train_0: 65000 waveforms\n",
      "  Train_0 processing 0/65000\n",
      "  Train_0 processing 5000/65000\n",
      "  Train_0 processing 10000/65000\n",
      "  Train_0 processing 15000/65000\n",
      "  Train_0 processing 20000/65000\n",
      "  Train_0 processing 25000/65000\n",
      "  Train_0 processing 30000/65000\n",
      "  Train_0 processing 35000/65000\n",
      "  Train_0 processing 40000/65000\n",
      "  Train_0 processing 45000/65000\n",
      "  Train_0 processing 50000/65000\n",
      "  Train_0 processing 55000/65000\n",
      "  Train_0 processing 60000/65000\n",
      "Loaded Train_1: 65000 waveforms\n",
      "  Train_1 processing 0/65000\n",
      "  Train_1 processing 5000/65000\n",
      "  Train_1 processing 10000/65000\n",
      "  Train_1 processing 15000/65000\n",
      "  Train_1 processing 20000/65000\n",
      "  Train_1 processing 25000/65000\n",
      "  Train_1 processing 30000/65000\n",
      "  Train_1 processing 35000/65000\n",
      "  Train_1 processing 40000/65000\n",
      "  Train_1 processing 45000/65000\n",
      "  Train_1 processing 50000/65000\n",
      "  Train_1 processing 55000/65000\n",
      "  Train_1 processing 60000/65000\n",
      "Loaded Train_2: 65000 waveforms\n",
      "  Train_2 processing 0/65000\n",
      "  Train_2 processing 5000/65000\n",
      "  Train_2 processing 10000/65000\n",
      "  Train_2 processing 15000/65000\n",
      "  Train_2 processing 20000/65000\n",
      "  Train_2 processing 25000/65000\n",
      "  Train_2 processing 30000/65000\n",
      "  Train_2 processing 35000/65000\n",
      "  Train_2 processing 40000/65000\n",
      "  Train_2 processing 45000/65000\n",
      "  Train_2 processing 50000/65000\n",
      "  Train_2 processing 55000/65000\n",
      "  Train_2 processing 60000/65000\n",
      "Loaded Train_3: 65000 waveforms\n",
      "  Train_3 processing 0/65000\n",
      "  Train_3 processing 5000/65000\n",
      "  Train_3 processing 10000/65000\n",
      "  Train_3 processing 15000/65000\n",
      "  Train_3 processing 20000/65000\n",
      "  Train_3 processing 25000/65000\n",
      "  Train_3 processing 30000/65000\n",
      "  Train_3 processing 35000/65000\n",
      "  Train_3 processing 40000/65000\n",
      "  Train_3 processing 45000/65000\n",
      "  Train_3 processing 50000/65000\n",
      "  Train_3 processing 55000/65000\n",
      "  Train_3 processing 60000/65000\n",
      "Loaded Train_4: 65000 waveforms\n",
      "  Train_4 processing 0/65000\n",
      "  Train_4 processing 5000/65000\n",
      "  Train_4 processing 10000/65000\n",
      "  Train_4 processing 15000/65000\n",
      "  Train_4 processing 20000/65000\n",
      "  Train_4 processing 25000/65000\n",
      "  Train_4 processing 30000/65000\n",
      "  Train_4 processing 35000/65000\n",
      "  Train_4 processing 40000/65000\n",
      "  Train_4 processing 45000/65000\n",
      "  Train_4 processing 50000/65000\n",
      "  Train_4 processing 55000/65000\n",
      "  Train_4 processing 60000/65000\n",
      "Loaded Train_5: 65000 waveforms\n",
      "  Train_5 processing 0/65000\n",
      "  Train_5 processing 5000/65000\n",
      "  Train_5 processing 10000/65000\n",
      "  Train_5 processing 15000/65000\n",
      "  Train_5 processing 20000/65000\n",
      "  Train_5 processing 25000/65000\n",
      "  Train_5 processing 30000/65000\n",
      "  Train_5 processing 35000/65000\n",
      "  Train_5 processing 40000/65000\n",
      "  Train_5 processing 45000/65000\n",
      "  Train_5 processing 50000/65000\n",
      "  Train_5 processing 55000/65000\n",
      "  Train_5 processing 60000/65000\n",
      "Loaded Train_6: 65000 waveforms\n",
      "  Train_6 processing 0/65000\n",
      "  Train_6 processing 5000/65000\n",
      "  Train_6 processing 10000/65000\n",
      "  Train_6 processing 15000/65000\n",
      "  Train_6 processing 20000/65000\n",
      "  Train_6 processing 25000/65000\n",
      "  Train_6 processing 30000/65000\n",
      "  Train_6 processing 35000/65000\n",
      "  Train_6 processing 40000/65000\n",
      "  Train_6 processing 45000/65000\n",
      "  Train_6 processing 50000/65000\n",
      "  Train_6 processing 55000/65000\n",
      "  Train_6 processing 60000/65000\n",
      "Loaded Train_7: 65000 waveforms\n",
      "  Train_7 processing 0/65000\n",
      "  Train_7 processing 5000/65000\n",
      "  Train_7 processing 10000/65000\n",
      "  Train_7 processing 15000/65000\n",
      "  Train_7 processing 20000/65000\n",
      "  Train_7 processing 25000/65000\n",
      "  Train_7 processing 30000/65000\n",
      "  Train_7 processing 35000/65000\n",
      "  Train_7 processing 40000/65000\n",
      "  Train_7 processing 45000/65000\n",
      "  Train_7 processing 50000/65000\n",
      "  Train_7 processing 55000/65000\n",
      "  Train_7 processing 60000/65000\n",
      "Loaded Train_8: 65000 waveforms\n",
      "  Train_8 processing 0/65000\n",
      "  Train_8 processing 5000/65000\n",
      "  Train_8 processing 10000/65000\n",
      "  Train_8 processing 15000/65000\n",
      "  Train_8 processing 20000/65000\n",
      "  Train_8 processing 25000/65000\n",
      "  Train_8 processing 30000/65000\n",
      "  Train_8 processing 35000/65000\n",
      "  Train_8 processing 40000/65000\n",
      "  Train_8 processing 45000/65000\n",
      "  Train_8 processing 50000/65000\n",
      "  Train_8 processing 55000/65000\n",
      "  Train_8 processing 60000/65000\n",
      "Loaded Train_9: 65000 waveforms\n",
      "  Train_9 processing 0/65000\n",
      "  Train_9 processing 5000/65000\n",
      "  Train_9 processing 10000/65000\n",
      "  Train_9 processing 15000/65000\n",
      "  Train_9 processing 20000/65000\n",
      "  Train_9 processing 25000/65000\n",
      "  Train_9 processing 30000/65000\n",
      "  Train_9 processing 35000/65000\n",
      "  Train_9 processing 40000/65000\n",
      "  Train_9 processing 45000/65000\n",
      "  Train_9 processing 50000/65000\n",
      "  Train_9 processing 55000/65000\n",
      "  Train_9 processing 60000/65000\n",
      "Loaded Train_10: 65000 waveforms\n",
      "  Train_10 processing 0/65000\n",
      "  Train_10 processing 5000/65000\n",
      "  Train_10 processing 10000/65000\n",
      "  Train_10 processing 15000/65000\n",
      "  Train_10 processing 20000/65000\n",
      "  Train_10 processing 25000/65000\n",
      "  Train_10 processing 30000/65000\n",
      "  Train_10 processing 35000/65000\n",
      "  Train_10 processing 40000/65000\n",
      "  Train_10 processing 45000/65000\n",
      "  Train_10 processing 50000/65000\n",
      "  Train_10 processing 55000/65000\n",
      "  Train_10 processing 60000/65000\n",
      "Loaded Train_11: 65000 waveforms\n",
      "  Train_11 processing 0/65000\n",
      "  Train_11 processing 5000/65000\n",
      "  Train_11 processing 10000/65000\n",
      "  Train_11 processing 15000/65000\n",
      "  Train_11 processing 20000/65000\n",
      "  Train_11 processing 25000/65000\n",
      "  Train_11 processing 30000/65000\n",
      "  Train_11 processing 35000/65000\n",
      "  Train_11 processing 40000/65000\n",
      "  Train_11 processing 45000/65000\n",
      "  Train_11 processing 50000/65000\n",
      "  Train_11 processing 55000/65000\n",
      "  Train_11 processing 60000/65000\n",
      "Loaded Train_12: 65000 waveforms\n",
      "  Train_12 processing 0/65000\n",
      "  Train_12 processing 5000/65000\n",
      "  Train_12 processing 10000/65000\n",
      "  Train_12 processing 15000/65000\n",
      "  Train_12 processing 20000/65000\n",
      "  Train_12 processing 25000/65000\n",
      "  Train_12 processing 30000/65000\n",
      "  Train_12 processing 35000/65000\n",
      "  Train_12 processing 40000/65000\n",
      "  Train_12 processing 45000/65000\n",
      "  Train_12 processing 50000/65000\n",
      "  Train_12 processing 55000/65000\n",
      "  Train_12 processing 60000/65000\n",
      "Loaded Train_13: 65000 waveforms\n",
      "  Train_13 processing 0/65000\n",
      "  Train_13 processing 5000/65000\n",
      "  Train_13 processing 10000/65000\n",
      "  Train_13 processing 15000/65000\n",
      "  Train_13 processing 20000/65000\n",
      "  Train_13 processing 25000/65000\n",
      "  Train_13 processing 30000/65000\n",
      "  Train_13 processing 35000/65000\n",
      "  Train_13 processing 40000/65000\n",
      "  Train_13 processing 45000/65000\n",
      "  Train_13 processing 50000/65000\n",
      "  Train_13 processing 55000/65000\n",
      "  Train_13 processing 60000/65000\n",
      "Loaded Train_14: 65000 waveforms\n",
      "  Train_14 processing 0/65000\n",
      "  Train_14 processing 5000/65000\n",
      "  Train_14 processing 10000/65000\n",
      "  Train_14 processing 15000/65000\n",
      "  Train_14 processing 20000/65000\n",
      "  Train_14 processing 25000/65000\n",
      "  Train_14 processing 30000/65000\n",
      "  Train_14 processing 35000/65000\n",
      "  Train_14 processing 40000/65000\n",
      "  Train_14 processing 45000/65000\n",
      "  Train_14 processing 50000/65000\n",
      "  Train_14 processing 55000/65000\n",
      "  Train_14 processing 60000/65000\n",
      "Loaded Train_15: 65000 waveforms\n",
      "  Train_15 processing 0/65000\n",
      "  Train_15 processing 5000/65000\n",
      "  Train_15 processing 10000/65000\n",
      "  Train_15 processing 15000/65000\n",
      "  Train_15 processing 20000/65000\n",
      "  Train_15 processing 25000/65000\n",
      "  Train_15 processing 30000/65000\n",
      "  Train_15 processing 35000/65000\n",
      "  Train_15 processing 40000/65000\n",
      "  Train_15 processing 45000/65000\n",
      "  Train_15 processing 50000/65000\n",
      "  Train_15 processing 55000/65000\n",
      "  Train_15 processing 60000/65000\n",
      "\n",
      "Saved combined HWP CSV to: finalcsveunice\\HWP_train_all.csv\n",
      "          id     HWP\n",
      "0  0_train_0  2299.0\n",
      "1  1_train_0  2446.0\n",
      "2  2_train_0  2262.0\n",
      "3  3_train_0  2833.0\n",
      "4  4_train_0  2397.0\n",
      "count    1.039995e+06\n",
      "mean     2.423961e+03\n",
      "std      3.925200e+02\n",
      "min      2.000000e+00\n",
      "25%      2.191000e+03\n",
      "50%      2.325000e+03\n",
      "75%      2.510000e+03\n",
      "max      3.799000e+03\n",
      "Name: HWP, dtype: float64\n",
      "NaNs: 5\n"
     ]
    }
   ],
   "source": [
    "all_ids = []\n",
    "all_HWP = []\n",
    "\n",
    "for train_idx in range(16):\n",
    "    train_file = f\"../data/old/MJD_Train_{train_idx}.hdf5\"\n",
    "    if not os.path.exists(train_file):\n",
    "        print(f\"Skipping missing file: {train_file}\")\n",
    "        continue\n",
    "\n",
    "    with h5py.File(train_file, \"r\") as f:\n",
    "        waveforms = np.array(f[\"raw_waveform\"])\n",
    "        ids = np.array(f[\"id\"])\n",
    "\n",
    "    print(f\"Loaded Train_{train_idx}: {len(waveforms)} waveforms\")\n",
    "\n",
    "    for i, wf in enumerate(waveforms):\n",
    "        if i % 5000 == 0:\n",
    "            print(f\"  Train_{train_idx} processing {i}/{len(waveforms)}\")\n",
    "\n",
    "        all_HWP.append(compute_HWP(wf))\n",
    "        all_ids.append(f\"{ids[i]}_train_{train_idx}\")\n",
    "\n",
    "all_HWP = np.array(all_HWP, dtype=float)\n",
    "\n",
    "\n",
    "df_hwp = pd.DataFrame({\n",
    "    \"id\": all_ids,\n",
    "    \"HWP\": all_HWP\n",
    "})\n",
    "\n",
    "output_path_hwp = os.path.join(OUTPUT_DIR, \"HWP_train_all.csv\")\n",
    "df_hwp.to_csv(output_path_hwp, index=False)\n",
    "\n",
    "print(\"\\nSaved combined HWP CSV to:\", output_path_hwp)\n",
    "print(df_hwp.head())\n",
    "print(df_hwp[\"HWP\"].describe())\n",
    "print(\"NaNs:\", df_hwp[\"HWP\"].isna().sum())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1575a80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NaNs: 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>HWP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>253720</th>\n",
       "      <td>253720_train_3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391741</th>\n",
       "      <td>391741_train_6</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524458</th>\n",
       "      <td>524458_train_8</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586359</th>\n",
       "      <td>586359_train_9</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>845815</th>\n",
       "      <td>845815_train_13</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id  HWP\n",
       "253720   253720_train_3  NaN\n",
       "391741   391741_train_6  NaN\n",
       "524458   524458_train_8  NaN\n",
       "586359   586359_train_9  NaN\n",
       "845815  845815_train_13  NaN"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nan_rows = df_hwp[df_hwp[\"HWP\"].isna()]\n",
    "\n",
    "print(\"Number of NaNs:\", len(nan_rows))\n",
    "nan_rows.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45006b34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\YooNi\\AppData\\Local\\Temp\\ipykernel_23696\\1757386066.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  nan_rows[\"train_idx\"] = nan_rows[\"id\"].str.extract(r\"_train_(\\d+)\").astype(int)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "train_idx\n",
       "3     1\n",
       "6     1\n",
       "8     1\n",
       "9     1\n",
       "13    1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nan_rows[\"train_idx\"] = nan_rows[\"id\"].str.extract(r\"_train_(\\d+)\").astype(int)\n",
    "\n",
    "nan_rows[\"train_idx\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9c3743",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7546006a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Test_0: 65000 waveforms\n",
      "  Test_0 processing 0/65000\n",
      "  Test_0 processing 5000/65000\n",
      "  Test_0 processing 10000/65000\n",
      "  Test_0 processing 15000/65000\n",
      "  Test_0 processing 20000/65000\n",
      "  Test_0 processing 25000/65000\n",
      "  Test_0 processing 30000/65000\n",
      "  Test_0 processing 35000/65000\n",
      "  Test_0 processing 40000/65000\n",
      "  Test_0 processing 45000/65000\n",
      "  Test_0 processing 50000/65000\n",
      "  Test_0 processing 55000/65000\n",
      "  Test_0 processing 60000/65000\n",
      "Loaded Test_1: 65000 waveforms\n",
      "  Test_1 processing 0/65000\n",
      "  Test_1 processing 5000/65000\n",
      "  Test_1 processing 10000/65000\n",
      "  Test_1 processing 15000/65000\n",
      "  Test_1 processing 20000/65000\n",
      "  Test_1 processing 25000/65000\n",
      "  Test_1 processing 30000/65000\n",
      "  Test_1 processing 35000/65000\n",
      "  Test_1 processing 40000/65000\n",
      "  Test_1 processing 45000/65000\n",
      "  Test_1 processing 50000/65000\n",
      "  Test_1 processing 55000/65000\n",
      "  Test_1 processing 60000/65000\n",
      "Loaded Test_2: 65000 waveforms\n",
      "  Test_2 processing 0/65000\n",
      "  Test_2 processing 5000/65000\n",
      "  Test_2 processing 10000/65000\n",
      "  Test_2 processing 15000/65000\n",
      "  Test_2 processing 20000/65000\n",
      "  Test_2 processing 25000/65000\n",
      "  Test_2 processing 30000/65000\n",
      "  Test_2 processing 35000/65000\n",
      "  Test_2 processing 40000/65000\n",
      "  Test_2 processing 45000/65000\n",
      "  Test_2 processing 50000/65000\n",
      "  Test_2 processing 55000/65000\n",
      "  Test_2 processing 60000/65000\n",
      "Loaded Test_3: 65000 waveforms\n",
      "  Test_3 processing 0/65000\n",
      "  Test_3 processing 5000/65000\n",
      "  Test_3 processing 10000/65000\n",
      "  Test_3 processing 15000/65000\n",
      "  Test_3 processing 20000/65000\n",
      "  Test_3 processing 25000/65000\n",
      "  Test_3 processing 30000/65000\n",
      "  Test_3 processing 35000/65000\n",
      "  Test_3 processing 40000/65000\n",
      "  Test_3 processing 45000/65000\n",
      "  Test_3 processing 50000/65000\n",
      "  Test_3 processing 55000/65000\n",
      "  Test_3 processing 60000/65000\n",
      "Loaded Test_4: 65000 waveforms\n",
      "  Test_4 processing 0/65000\n",
      "  Test_4 processing 5000/65000\n",
      "  Test_4 processing 10000/65000\n",
      "  Test_4 processing 15000/65000\n",
      "  Test_4 processing 20000/65000\n",
      "  Test_4 processing 25000/65000\n",
      "  Test_4 processing 30000/65000\n",
      "  Test_4 processing 35000/65000\n",
      "  Test_4 processing 40000/65000\n",
      "  Test_4 processing 45000/65000\n",
      "  Test_4 processing 50000/65000\n",
      "  Test_4 processing 55000/65000\n",
      "  Test_4 processing 60000/65000\n",
      "Loaded Test_5: 65000 waveforms\n",
      "  Test_5 processing 0/65000\n",
      "  Test_5 processing 5000/65000\n",
      "  Test_5 processing 10000/65000\n",
      "  Test_5 processing 15000/65000\n",
      "  Test_5 processing 20000/65000\n",
      "  Test_5 processing 25000/65000\n",
      "  Test_5 processing 30000/65000\n",
      "  Test_5 processing 35000/65000\n",
      "  Test_5 processing 40000/65000\n",
      "  Test_5 processing 45000/65000\n",
      "  Test_5 processing 50000/65000\n",
      "  Test_5 processing 55000/65000\n",
      "  Test_5 processing 60000/65000\n",
      "\n",
      "Saved combined HWP TEST CSV to: finalcsveunice\\HWP_test_all.csv\n",
      "               id     HWP\n",
      "0  2395098_test_0  2140.0\n",
      "1  2395099_test_0  2137.0\n",
      "2  2395100_test_0  2279.0\n",
      "3  2395101_test_0  2247.0\n",
      "4  2395102_test_0  2687.0\n",
      "count    390000.000000\n",
      "mean       2423.576249\n",
      "std         391.521884\n",
      "min          20.000000\n",
      "25%        2191.000000\n",
      "50%        2325.000000\n",
      "75%        2510.000000\n",
      "max        3799.000000\n",
      "Name: HWP, dtype: float64\n",
      "NaNs: 0\n"
     ]
    }
   ],
   "source": [
    "# test file \n",
    "all_test_ids = []\n",
    "all_test_HWP = []\n",
    "\n",
    "for test_idx in range(6):\n",
    "    test_file = f\"../data/old/MJD_Test_{test_idx}.hdf5\"\n",
    "    if not os.path.exists(test_file):\n",
    "        print(f\"Skipping missing file: {test_file}\")\n",
    "        continue\n",
    "\n",
    "    with h5py.File(test_file, \"r\") as f:\n",
    "        waveforms = np.array(f[\"raw_waveform\"])\n",
    "        ids = np.array(f[\"id\"])\n",
    "\n",
    "    print(f\"Loaded Test_{test_idx}: {len(waveforms)} waveforms\")\n",
    "\n",
    "    for i, wf in enumerate(waveforms):\n",
    "        if i % 5000 == 0:\n",
    "            print(f\"  Test_{test_idx} processing {i}/{len(waveforms)}\")\n",
    "\n",
    "        all_test_HWP.append(compute_HWP(wf))\n",
    "        all_test_ids.append(f\"{ids[i]}_test_{test_idx}\")\n",
    "\n",
    "all_test_HWP = np.array(all_test_HWP, dtype=float)\n",
    "all_test_HWP[~np.isfinite(all_test_HWP)] = np.nan\n",
    "\n",
    "df_hwp_test = pd.DataFrame({\n",
    "    \"id\": all_test_ids,\n",
    "    \"HWP\": all_test_HWP\n",
    "})\n",
    "\n",
    "output_path_hwp_test = os.path.join(OUTPUT_DIR, \"HWP_test_all.csv\")\n",
    "df_hwp_test.to_csv(output_path_hwp_test, index=False)\n",
    "\n",
    "print(\"\\nSaved combined HWP TEST CSV to:\", output_path_hwp_test)\n",
    "print(df_hwp_test.head())\n",
    "print(df_hwp_test[\"HWP\"].describe())\n",
    "print(\"NaNs:\", df_hwp_test[\"HWP\"].isna().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f051dc9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
