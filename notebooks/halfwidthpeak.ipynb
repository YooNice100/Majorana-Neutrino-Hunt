{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "495939fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added to Python path: c:\\Users\\YooNi\\OneDrive\\Desktop\\Majorana-Neutrino-Hunt\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Get the project root (one level above notebooks/)\n",
    "project_root = os.path.abspath(\"..\")\n",
    "sys.path.append(project_root)\n",
    "\n",
    "print(\"Added to Python path:\", project_root)\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# from src.parameters.tail_features import compute_LQ80\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f0ce8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_file = \"../data/old/MJD_Train_0.hdf5\"\n",
    "\n",
    "# with h5py.File(train_file, \"r\") as f:\n",
    "#     waveforms = np.array(f[\"raw_waveform\"])\n",
    "#     ids = np.array(f[\"id\"])\n",
    "\n",
    "# print(\"Loaded\", len(waveforms), \"waveforms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f504d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_HWP(waveform):\n",
    "    y = np.asarray(waveform, dtype=float)\n",
    "\n",
    "    peak_val = float(np.max(y))\n",
    "    if peak_val <= 0:\n",
    "        return np.nan\n",
    "\n",
    "    level25 = 0.25 * peak_val\n",
    "    level75 = 0.75 * peak_val\n",
    "\n",
    "    above_25 = np.where(y >= level25)[0]\n",
    "    above_75 = np.where(y >= level75)[0]\n",
    "\n",
    "    if len(above_25) == 0 or len(above_75) == 0:\n",
    "        return np.nan\n",
    "\n",
    "    left_idx = int(above_25[0])\n",
    "    right_idx = int(above_75[-1])\n",
    "\n",
    "    width = right_idx - left_idx\n",
    "    if width < 0:\n",
    "        return np.nan\n",
    "\n",
    "    return float(width)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9aade5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d16e7663",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # compute HWP for everything\n",
    "# HWP_values = []\n",
    "\n",
    "# for i, wf in enumerate(waveforms):\n",
    "#     if i % 5000 == 0:\n",
    "#         print(f\"Processing {i} / {len(waveforms)}\")\n",
    "#     HWP_values.append(compute_HWP(wf))\n",
    "\n",
    "# HWP_values = np.array(HWP_values, dtype=float)\n",
    "# HWP_values[~np.isfinite(HWP_values)] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0ee0a795",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # output\n",
    "# formatted_ids = [f\"{id_}_train_0\" for id_ in ids]\n",
    "\n",
    "# df = pd.DataFrame({\n",
    "#     \"id\": formatted_ids,\n",
    "#     \"HWP\": HWP_values\n",
    "# })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7f586220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_path = \"HWP_train_0.csv\"\n",
    "# df.to_csv(output_path, index=False)\n",
    "# print(\"Saved to\", output_path)\n",
    "# print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6f0a242c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df[\"HWP\"].describe())\n",
    "# print(\"NaNs:\", df[\"HWP\"].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10ef2d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec19a70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c4da3ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# vals = df[\"HWP\"].to_numpy(dtype=float)\n",
    "# vals = vals[np.isfinite(vals)]\n",
    "\n",
    "# plt.figure()\n",
    "# plt.hist(vals, bins=200)\n",
    "# plt.yscale(\"log\")\n",
    "# plt.xlabel(\"HWP (samples)\")\n",
    "# plt.ylabel(\"Count\")\n",
    "# plt.title(\"Half Width Peak (HWP) Distribution â€“ Train 0\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ebb640",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4c8e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIR = \"finalcsveunice\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3172d8a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Train_0: 65000 waveforms\n",
      "  Train_0 processing 0/65000\n",
      "  Train_0 processing 5000/65000\n",
      "  Train_0 processing 10000/65000\n",
      "  Train_0 processing 15000/65000\n",
      "  Train_0 processing 20000/65000\n",
      "  Train_0 processing 25000/65000\n",
      "  Train_0 processing 30000/65000\n",
      "  Train_0 processing 35000/65000\n",
      "  Train_0 processing 40000/65000\n",
      "  Train_0 processing 45000/65000\n",
      "  Train_0 processing 50000/65000\n",
      "  Train_0 processing 55000/65000\n",
      "  Train_0 processing 60000/65000\n",
      "Loaded Train_1: 65000 waveforms\n",
      "  Train_1 processing 0/65000\n",
      "  Train_1 processing 5000/65000\n",
      "  Train_1 processing 10000/65000\n",
      "  Train_1 processing 15000/65000\n",
      "  Train_1 processing 20000/65000\n",
      "  Train_1 processing 25000/65000\n",
      "  Train_1 processing 30000/65000\n",
      "  Train_1 processing 35000/65000\n",
      "  Train_1 processing 40000/65000\n",
      "  Train_1 processing 45000/65000\n",
      "  Train_1 processing 50000/65000\n",
      "  Train_1 processing 55000/65000\n",
      "  Train_1 processing 60000/65000\n",
      "Loaded Train_2: 65000 waveforms\n",
      "  Train_2 processing 0/65000\n",
      "  Train_2 processing 5000/65000\n",
      "  Train_2 processing 10000/65000\n",
      "  Train_2 processing 15000/65000\n",
      "  Train_2 processing 20000/65000\n",
      "  Train_2 processing 25000/65000\n",
      "  Train_2 processing 30000/65000\n",
      "  Train_2 processing 35000/65000\n",
      "  Train_2 processing 40000/65000\n",
      "  Train_2 processing 45000/65000\n",
      "  Train_2 processing 50000/65000\n",
      "  Train_2 processing 55000/65000\n",
      "  Train_2 processing 60000/65000\n",
      "Loaded Train_3: 65000 waveforms\n",
      "  Train_3 processing 0/65000\n",
      "  Train_3 processing 5000/65000\n",
      "  Train_3 processing 10000/65000\n",
      "  Train_3 processing 15000/65000\n",
      "  Train_3 processing 20000/65000\n",
      "  Train_3 processing 25000/65000\n",
      "  Train_3 processing 30000/65000\n",
      "  Train_3 processing 35000/65000\n",
      "  Train_3 processing 40000/65000\n",
      "  Train_3 processing 45000/65000\n",
      "  Train_3 processing 50000/65000\n",
      "  Train_3 processing 55000/65000\n",
      "  Train_3 processing 60000/65000\n",
      "Loaded Train_4: 65000 waveforms\n",
      "  Train_4 processing 0/65000\n",
      "  Train_4 processing 5000/65000\n",
      "  Train_4 processing 10000/65000\n",
      "  Train_4 processing 15000/65000\n",
      "  Train_4 processing 20000/65000\n",
      "  Train_4 processing 25000/65000\n",
      "  Train_4 processing 30000/65000\n",
      "  Train_4 processing 35000/65000\n",
      "  Train_4 processing 40000/65000\n",
      "  Train_4 processing 45000/65000\n",
      "  Train_4 processing 50000/65000\n",
      "  Train_4 processing 55000/65000\n",
      "  Train_4 processing 60000/65000\n",
      "Loaded Train_5: 65000 waveforms\n",
      "  Train_5 processing 0/65000\n",
      "  Train_5 processing 5000/65000\n",
      "  Train_5 processing 10000/65000\n",
      "  Train_5 processing 15000/65000\n",
      "  Train_5 processing 20000/65000\n",
      "  Train_5 processing 25000/65000\n",
      "  Train_5 processing 30000/65000\n",
      "  Train_5 processing 35000/65000\n",
      "  Train_5 processing 40000/65000\n",
      "  Train_5 processing 45000/65000\n",
      "  Train_5 processing 50000/65000\n",
      "  Train_5 processing 55000/65000\n",
      "  Train_5 processing 60000/65000\n",
      "Loaded Train_6: 65000 waveforms\n",
      "  Train_6 processing 0/65000\n",
      "  Train_6 processing 5000/65000\n",
      "  Train_6 processing 10000/65000\n",
      "  Train_6 processing 15000/65000\n",
      "  Train_6 processing 20000/65000\n",
      "  Train_6 processing 25000/65000\n",
      "  Train_6 processing 30000/65000\n",
      "  Train_6 processing 35000/65000\n",
      "  Train_6 processing 40000/65000\n",
      "  Train_6 processing 45000/65000\n",
      "  Train_6 processing 50000/65000\n",
      "  Train_6 processing 55000/65000\n",
      "  Train_6 processing 60000/65000\n",
      "Loaded Train_7: 65000 waveforms\n",
      "  Train_7 processing 0/65000\n",
      "  Train_7 processing 5000/65000\n",
      "  Train_7 processing 10000/65000\n",
      "  Train_7 processing 15000/65000\n",
      "  Train_7 processing 20000/65000\n",
      "  Train_7 processing 25000/65000\n",
      "  Train_7 processing 30000/65000\n",
      "  Train_7 processing 35000/65000\n",
      "  Train_7 processing 40000/65000\n",
      "  Train_7 processing 45000/65000\n",
      "  Train_7 processing 50000/65000\n",
      "  Train_7 processing 55000/65000\n",
      "  Train_7 processing 60000/65000\n",
      "Loaded Train_8: 65000 waveforms\n",
      "  Train_8 processing 0/65000\n",
      "  Train_8 processing 5000/65000\n",
      "  Train_8 processing 10000/65000\n",
      "  Train_8 processing 15000/65000\n",
      "  Train_8 processing 20000/65000\n",
      "  Train_8 processing 25000/65000\n",
      "  Train_8 processing 30000/65000\n",
      "  Train_8 processing 35000/65000\n",
      "  Train_8 processing 40000/65000\n",
      "  Train_8 processing 45000/65000\n",
      "  Train_8 processing 50000/65000\n",
      "  Train_8 processing 55000/65000\n",
      "  Train_8 processing 60000/65000\n",
      "Loaded Train_9: 65000 waveforms\n",
      "  Train_9 processing 0/65000\n",
      "  Train_9 processing 5000/65000\n",
      "  Train_9 processing 10000/65000\n",
      "  Train_9 processing 15000/65000\n",
      "  Train_9 processing 20000/65000\n",
      "  Train_9 processing 25000/65000\n",
      "  Train_9 processing 30000/65000\n",
      "  Train_9 processing 35000/65000\n",
      "  Train_9 processing 40000/65000\n",
      "  Train_9 processing 45000/65000\n",
      "  Train_9 processing 50000/65000\n",
      "  Train_9 processing 55000/65000\n",
      "  Train_9 processing 60000/65000\n",
      "Loaded Train_10: 65000 waveforms\n",
      "  Train_10 processing 0/65000\n",
      "  Train_10 processing 5000/65000\n",
      "  Train_10 processing 10000/65000\n",
      "  Train_10 processing 15000/65000\n",
      "  Train_10 processing 20000/65000\n",
      "  Train_10 processing 25000/65000\n",
      "  Train_10 processing 30000/65000\n",
      "  Train_10 processing 35000/65000\n",
      "  Train_10 processing 40000/65000\n",
      "  Train_10 processing 45000/65000\n",
      "  Train_10 processing 50000/65000\n",
      "  Train_10 processing 55000/65000\n",
      "  Train_10 processing 60000/65000\n",
      "Loaded Train_11: 65000 waveforms\n",
      "  Train_11 processing 0/65000\n",
      "  Train_11 processing 5000/65000\n",
      "  Train_11 processing 10000/65000\n",
      "  Train_11 processing 15000/65000\n",
      "  Train_11 processing 20000/65000\n",
      "  Train_11 processing 25000/65000\n",
      "  Train_11 processing 30000/65000\n",
      "  Train_11 processing 35000/65000\n",
      "  Train_11 processing 40000/65000\n",
      "  Train_11 processing 45000/65000\n",
      "  Train_11 processing 50000/65000\n",
      "  Train_11 processing 55000/65000\n",
      "  Train_11 processing 60000/65000\n",
      "Loaded Train_12: 65000 waveforms\n",
      "  Train_12 processing 0/65000\n",
      "  Train_12 processing 5000/65000\n",
      "  Train_12 processing 10000/65000\n",
      "  Train_12 processing 15000/65000\n",
      "  Train_12 processing 20000/65000\n",
      "  Train_12 processing 25000/65000\n",
      "  Train_12 processing 30000/65000\n",
      "  Train_12 processing 35000/65000\n",
      "  Train_12 processing 40000/65000\n",
      "  Train_12 processing 45000/65000\n",
      "  Train_12 processing 50000/65000\n",
      "  Train_12 processing 55000/65000\n",
      "  Train_12 processing 60000/65000\n",
      "Loaded Train_13: 65000 waveforms\n",
      "  Train_13 processing 0/65000\n",
      "  Train_13 processing 5000/65000\n",
      "  Train_13 processing 10000/65000\n",
      "  Train_13 processing 15000/65000\n",
      "  Train_13 processing 20000/65000\n",
      "  Train_13 processing 25000/65000\n",
      "  Train_13 processing 30000/65000\n",
      "  Train_13 processing 35000/65000\n",
      "  Train_13 processing 40000/65000\n",
      "  Train_13 processing 45000/65000\n",
      "  Train_13 processing 50000/65000\n",
      "  Train_13 processing 55000/65000\n",
      "  Train_13 processing 60000/65000\n",
      "Loaded Train_14: 65000 waveforms\n",
      "  Train_14 processing 0/65000\n",
      "  Train_14 processing 5000/65000\n",
      "  Train_14 processing 10000/65000\n",
      "  Train_14 processing 15000/65000\n",
      "  Train_14 processing 20000/65000\n",
      "  Train_14 processing 25000/65000\n",
      "  Train_14 processing 30000/65000\n",
      "  Train_14 processing 35000/65000\n",
      "  Train_14 processing 40000/65000\n",
      "  Train_14 processing 45000/65000\n",
      "  Train_14 processing 50000/65000\n",
      "  Train_14 processing 55000/65000\n",
      "  Train_14 processing 60000/65000\n",
      "Loaded Train_15: 65000 waveforms\n",
      "  Train_15 processing 0/65000\n",
      "  Train_15 processing 5000/65000\n",
      "  Train_15 processing 10000/65000\n",
      "  Train_15 processing 15000/65000\n",
      "  Train_15 processing 20000/65000\n",
      "  Train_15 processing 25000/65000\n",
      "  Train_15 processing 30000/65000\n",
      "  Train_15 processing 35000/65000\n",
      "  Train_15 processing 40000/65000\n",
      "  Train_15 processing 45000/65000\n",
      "  Train_15 processing 50000/65000\n",
      "  Train_15 processing 55000/65000\n",
      "  Train_15 processing 60000/65000\n",
      "\n",
      "Saved combined HWP CSV to: finalcsveunice\\HWP_train_all.csv\n",
      "          id     HWP\n",
      "0  0_train_0  2299.0\n",
      "1  1_train_0  2446.0\n",
      "2  2_train_0  2262.0\n",
      "3  3_train_0  2833.0\n",
      "4  4_train_0  2397.0\n",
      "count    1.039995e+06\n",
      "mean     2.423961e+03\n",
      "std      3.925200e+02\n",
      "min      2.000000e+00\n",
      "25%      2.191000e+03\n",
      "50%      2.325000e+03\n",
      "75%      2.510000e+03\n",
      "max      3.799000e+03\n",
      "Name: HWP, dtype: float64\n",
      "NaNs: 5\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "all_ids = []\n",
    "all_HWP = []\n",
    "\n",
    "for train_idx in range(16):\n",
    "    train_file = f\"../data/old/MJD_Train_{train_idx}.hdf5\"\n",
    "    if not os.path.exists(train_file):\n",
    "        print(f\"Skipping missing file: {train_file}\")\n",
    "        continue\n",
    "\n",
    "    with h5py.File(train_file, \"r\") as f:\n",
    "        waveforms = np.array(f[\"raw_waveform\"])\n",
    "        ids = np.array(f[\"id\"])\n",
    "\n",
    "    print(f\"Loaded Train_{train_idx}: {len(waveforms)} waveforms\")\n",
    "\n",
    "    for i, wf in enumerate(waveforms):\n",
    "        if i % 5000 == 0:\n",
    "            print(f\"  Train_{train_idx} processing {i}/{len(waveforms)}\")\n",
    "\n",
    "        all_HWP.append(compute_HWP(wf))\n",
    "        all_ids.append(f\"{ids[i]}_train_{train_idx}\")\n",
    "\n",
    "all_HWP = np.array(all_HWP, dtype=float)\n",
    "all_HWP[~np.isfinite(all_HWP)] = np.nan\n",
    "\n",
    "df_hwp = pd.DataFrame({\n",
    "    \"id\": all_ids,\n",
    "    \"HWP\": all_HWP\n",
    "})\n",
    "\n",
    "output_path_hwp = os.path.join(OUTPUT_DIR, \"HWP_train_all.csv\")\n",
    "df_hwp.to_csv(output_path_hwp, index=False)\n",
    "\n",
    "print(\"\\nSaved combined HWP CSV to:\", output_path_hwp)\n",
    "print(df_hwp.head())\n",
    "print(df_hwp[\"HWP\"].describe())\n",
    "print(\"NaNs:\", df_hwp[\"HWP\"].isna().sum())\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
