{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef140a8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added to Python path: c:\\Users\\YooNi\\OneDrive\\Desktop\\Majorana-Neutrino-Hunt\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "\n",
    "# Get the project root (one level above notebooks/)\n",
    "project_root = os.path.abspath(\"..\")\n",
    "sys.path.append(project_root)\n",
    "\n",
    "print(\"Added to Python path:\", project_root)\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# from src.parameters.tail_features import compute_LQ80\n",
    "from scipy.fft import rfft, rfftfreq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02dd0a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_file = \"../data/old/MJD_Train_0.hdf5\"\n",
    "\n",
    "# with h5py.File(train_file, \"r\") as f:\n",
    "#     waveforms = np.array(f[\"raw_waveform\"])\n",
    "#     ids = np.array(f[\"id\"])\n",
    "\n",
    "# print(\"Loaded\", len(waveforms), \"waveforms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42fbfbda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bdfc2b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_frequency_spectrum(waveform, sample_spacing=1.0):\n",
    "    \"\"\"\n",
    "    Computes one-sided FFT amplitude spectrum of the waveform.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    waveform : array-like\n",
    "        The signal to transform.\n",
    "    sample_spacing : float\n",
    "        Time step between samples.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    xf : np.ndarray\n",
    "        Frequencies.\n",
    "    amplitude : np.ndarray\n",
    "        Real amplitude spectrum.\n",
    "    \"\"\"\n",
    "    wf = np.asarray(waveform, dtype=float)\n",
    "    wf = wf - np.mean(wf[:200])\n",
    "    \n",
    "    N = len(wf)\n",
    "\n",
    "    yf = rfft(wf)\n",
    "    xf = rfftfreq(N, d=sample_spacing)\n",
    "\n",
    "    amplitude = np.abs(yf) * 2.0 / N\n",
    "    return xf, amplitude\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4f3fb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_spectral_centroid(waveform, sample_spacing=1.0):\n",
    "    freqs, amp = compute_frequency_spectrum(waveform, sample_spacing)\n",
    "\n",
    "    total_amp = np.sum(amp)\n",
    "    if total_amp == 0:\n",
    "        return 0.0\n",
    "\n",
    "    centroid = np.sum(freqs * amp) / total_amp\n",
    "    return float(centroid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59dc26a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25d7f10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIR = \"finalcsveunice\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d42197db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Train_0: 65000 waveforms\n",
      "  Train_0 processing 0/65000\n",
      "  Train_0 processing 5000/65000\n",
      "  Train_0 processing 10000/65000\n",
      "  Train_0 processing 15000/65000\n",
      "  Train_0 processing 20000/65000\n",
      "  Train_0 processing 25000/65000\n",
      "  Train_0 processing 30000/65000\n",
      "  Train_0 processing 35000/65000\n",
      "  Train_0 processing 40000/65000\n",
      "  Train_0 processing 45000/65000\n",
      "  Train_0 processing 50000/65000\n",
      "  Train_0 processing 55000/65000\n",
      "  Train_0 processing 60000/65000\n",
      "Loaded Train_1: 65000 waveforms\n",
      "  Train_1 processing 0/65000\n",
      "  Train_1 processing 5000/65000\n",
      "  Train_1 processing 10000/65000\n",
      "  Train_1 processing 15000/65000\n",
      "  Train_1 processing 20000/65000\n",
      "  Train_1 processing 25000/65000\n",
      "  Train_1 processing 30000/65000\n",
      "  Train_1 processing 35000/65000\n",
      "  Train_1 processing 40000/65000\n",
      "  Train_1 processing 45000/65000\n",
      "  Train_1 processing 50000/65000\n",
      "  Train_1 processing 55000/65000\n",
      "  Train_1 processing 60000/65000\n",
      "Loaded Train_2: 65000 waveforms\n",
      "  Train_2 processing 0/65000\n",
      "  Train_2 processing 5000/65000\n",
      "  Train_2 processing 10000/65000\n",
      "  Train_2 processing 15000/65000\n",
      "  Train_2 processing 20000/65000\n",
      "  Train_2 processing 25000/65000\n",
      "  Train_2 processing 30000/65000\n",
      "  Train_2 processing 35000/65000\n",
      "  Train_2 processing 40000/65000\n",
      "  Train_2 processing 45000/65000\n",
      "  Train_2 processing 50000/65000\n",
      "  Train_2 processing 55000/65000\n",
      "  Train_2 processing 60000/65000\n",
      "Loaded Train_3: 65000 waveforms\n",
      "  Train_3 processing 0/65000\n",
      "  Train_3 processing 5000/65000\n",
      "  Train_3 processing 10000/65000\n",
      "  Train_3 processing 15000/65000\n",
      "  Train_3 processing 20000/65000\n",
      "  Train_3 processing 25000/65000\n",
      "  Train_3 processing 30000/65000\n",
      "  Train_3 processing 35000/65000\n",
      "  Train_3 processing 40000/65000\n",
      "  Train_3 processing 45000/65000\n",
      "  Train_3 processing 50000/65000\n",
      "  Train_3 processing 55000/65000\n",
      "  Train_3 processing 60000/65000\n",
      "Loaded Train_4: 65000 waveforms\n",
      "  Train_4 processing 0/65000\n",
      "  Train_4 processing 5000/65000\n",
      "  Train_4 processing 10000/65000\n",
      "  Train_4 processing 15000/65000\n",
      "  Train_4 processing 20000/65000\n",
      "  Train_4 processing 25000/65000\n",
      "  Train_4 processing 30000/65000\n",
      "  Train_4 processing 35000/65000\n",
      "  Train_4 processing 40000/65000\n",
      "  Train_4 processing 45000/65000\n",
      "  Train_4 processing 50000/65000\n",
      "  Train_4 processing 55000/65000\n",
      "  Train_4 processing 60000/65000\n",
      "Loaded Train_5: 65000 waveforms\n",
      "  Train_5 processing 0/65000\n",
      "  Train_5 processing 5000/65000\n",
      "  Train_5 processing 10000/65000\n",
      "  Train_5 processing 15000/65000\n",
      "  Train_5 processing 20000/65000\n",
      "  Train_5 processing 25000/65000\n",
      "  Train_5 processing 30000/65000\n",
      "  Train_5 processing 35000/65000\n",
      "  Train_5 processing 40000/65000\n",
      "  Train_5 processing 45000/65000\n",
      "  Train_5 processing 50000/65000\n",
      "  Train_5 processing 55000/65000\n",
      "  Train_5 processing 60000/65000\n",
      "Loaded Train_6: 65000 waveforms\n",
      "  Train_6 processing 0/65000\n",
      "  Train_6 processing 5000/65000\n",
      "  Train_6 processing 10000/65000\n",
      "  Train_6 processing 15000/65000\n",
      "  Train_6 processing 20000/65000\n",
      "  Train_6 processing 25000/65000\n",
      "  Train_6 processing 30000/65000\n",
      "  Train_6 processing 35000/65000\n",
      "  Train_6 processing 40000/65000\n",
      "  Train_6 processing 45000/65000\n",
      "  Train_6 processing 50000/65000\n",
      "  Train_6 processing 55000/65000\n",
      "  Train_6 processing 60000/65000\n",
      "Loaded Train_7: 65000 waveforms\n",
      "  Train_7 processing 0/65000\n",
      "  Train_7 processing 5000/65000\n",
      "  Train_7 processing 10000/65000\n",
      "  Train_7 processing 15000/65000\n",
      "  Train_7 processing 20000/65000\n",
      "  Train_7 processing 25000/65000\n",
      "  Train_7 processing 30000/65000\n",
      "  Train_7 processing 35000/65000\n",
      "  Train_7 processing 40000/65000\n",
      "  Train_7 processing 45000/65000\n",
      "  Train_7 processing 50000/65000\n",
      "  Train_7 processing 55000/65000\n",
      "  Train_7 processing 60000/65000\n",
      "Loaded Train_8: 65000 waveforms\n",
      "  Train_8 processing 0/65000\n",
      "  Train_8 processing 5000/65000\n",
      "  Train_8 processing 10000/65000\n",
      "  Train_8 processing 15000/65000\n",
      "  Train_8 processing 20000/65000\n",
      "  Train_8 processing 25000/65000\n",
      "  Train_8 processing 30000/65000\n",
      "  Train_8 processing 35000/65000\n",
      "  Train_8 processing 40000/65000\n",
      "  Train_8 processing 45000/65000\n",
      "  Train_8 processing 50000/65000\n",
      "  Train_8 processing 55000/65000\n",
      "  Train_8 processing 60000/65000\n",
      "Loaded Train_9: 65000 waveforms\n",
      "  Train_9 processing 0/65000\n",
      "  Train_9 processing 5000/65000\n",
      "  Train_9 processing 10000/65000\n",
      "  Train_9 processing 15000/65000\n",
      "  Train_9 processing 20000/65000\n",
      "  Train_9 processing 25000/65000\n",
      "  Train_9 processing 30000/65000\n",
      "  Train_9 processing 35000/65000\n",
      "  Train_9 processing 40000/65000\n",
      "  Train_9 processing 45000/65000\n",
      "  Train_9 processing 50000/65000\n",
      "  Train_9 processing 55000/65000\n",
      "  Train_9 processing 60000/65000\n",
      "Loaded Train_10: 65000 waveforms\n",
      "  Train_10 processing 0/65000\n",
      "  Train_10 processing 5000/65000\n",
      "  Train_10 processing 10000/65000\n",
      "  Train_10 processing 15000/65000\n",
      "  Train_10 processing 20000/65000\n",
      "  Train_10 processing 25000/65000\n",
      "  Train_10 processing 30000/65000\n",
      "  Train_10 processing 35000/65000\n",
      "  Train_10 processing 40000/65000\n",
      "  Train_10 processing 45000/65000\n",
      "  Train_10 processing 50000/65000\n",
      "  Train_10 processing 55000/65000\n",
      "  Train_10 processing 60000/65000\n",
      "Loaded Train_11: 65000 waveforms\n",
      "  Train_11 processing 0/65000\n",
      "  Train_11 processing 5000/65000\n",
      "  Train_11 processing 10000/65000\n",
      "  Train_11 processing 15000/65000\n",
      "  Train_11 processing 20000/65000\n",
      "  Train_11 processing 25000/65000\n",
      "  Train_11 processing 30000/65000\n",
      "  Train_11 processing 35000/65000\n",
      "  Train_11 processing 40000/65000\n",
      "  Train_11 processing 45000/65000\n",
      "  Train_11 processing 50000/65000\n",
      "  Train_11 processing 55000/65000\n",
      "  Train_11 processing 60000/65000\n",
      "Loaded Train_12: 65000 waveforms\n",
      "  Train_12 processing 0/65000\n",
      "  Train_12 processing 5000/65000\n",
      "  Train_12 processing 10000/65000\n",
      "  Train_12 processing 15000/65000\n",
      "  Train_12 processing 20000/65000\n",
      "  Train_12 processing 25000/65000\n",
      "  Train_12 processing 30000/65000\n",
      "  Train_12 processing 35000/65000\n",
      "  Train_12 processing 40000/65000\n",
      "  Train_12 processing 45000/65000\n",
      "  Train_12 processing 50000/65000\n",
      "  Train_12 processing 55000/65000\n",
      "  Train_12 processing 60000/65000\n",
      "Loaded Train_13: 65000 waveforms\n",
      "  Train_13 processing 0/65000\n",
      "  Train_13 processing 5000/65000\n",
      "  Train_13 processing 10000/65000\n",
      "  Train_13 processing 15000/65000\n",
      "  Train_13 processing 20000/65000\n",
      "  Train_13 processing 25000/65000\n",
      "  Train_13 processing 30000/65000\n",
      "  Train_13 processing 35000/65000\n",
      "  Train_13 processing 40000/65000\n",
      "  Train_13 processing 45000/65000\n",
      "  Train_13 processing 50000/65000\n",
      "  Train_13 processing 55000/65000\n",
      "  Train_13 processing 60000/65000\n",
      "Loaded Train_14: 65000 waveforms\n",
      "  Train_14 processing 0/65000\n",
      "  Train_14 processing 5000/65000\n",
      "  Train_14 processing 10000/65000\n",
      "  Train_14 processing 15000/65000\n",
      "  Train_14 processing 20000/65000\n",
      "  Train_14 processing 25000/65000\n",
      "  Train_14 processing 30000/65000\n",
      "  Train_14 processing 35000/65000\n",
      "  Train_14 processing 40000/65000\n",
      "  Train_14 processing 45000/65000\n",
      "  Train_14 processing 50000/65000\n",
      "  Train_14 processing 55000/65000\n",
      "  Train_14 processing 60000/65000\n",
      "Loaded Train_15: 65000 waveforms\n",
      "  Train_15 processing 0/65000\n",
      "  Train_15 processing 5000/65000\n",
      "  Train_15 processing 10000/65000\n",
      "  Train_15 processing 15000/65000\n",
      "  Train_15 processing 20000/65000\n",
      "  Train_15 processing 25000/65000\n",
      "  Train_15 processing 30000/65000\n",
      "  Train_15 processing 35000/65000\n",
      "  Train_15 processing 40000/65000\n",
      "  Train_15 processing 45000/65000\n",
      "  Train_15 processing 50000/65000\n",
      "  Train_15 processing 55000/65000\n",
      "  Train_15 processing 60000/65000\n",
      "\n",
      "Saved combined SCA TRAIN CSV to: finalcsveunice\\SCA_train_all.csv\n",
      "          id       SCA\n",
      "0  0_train_0  0.034655\n",
      "1  1_train_0  0.035314\n",
      "2  2_train_0  0.034915\n",
      "3  3_train_0  0.034752\n",
      "4  4_train_0  0.035132\n",
      "count    1.040000e+06\n",
      "mean     3.572992e-02\n",
      "std      6.330801e-03\n",
      "min      2.676319e-02\n",
      "25%      3.452545e-02\n",
      "50%      3.480813e-02\n",
      "75%      3.524030e-02\n",
      "max      2.028693e-01\n",
      "Name: SCA, dtype: float64\n",
      "NaNs: 0\n"
     ]
    }
   ],
   "source": [
    "all_train_ids_sca = []\n",
    "all_SCA_train = []\n",
    "\n",
    "for train_idx in range(16):\n",
    "    train_file = f\"../data/old/MJD_Train_{train_idx}.hdf5\"\n",
    "    if not os.path.exists(train_file):\n",
    "        print(f\"Skipping missing file: {train_file}\")\n",
    "        continue\n",
    "\n",
    "    with h5py.File(train_file, \"r\") as f:\n",
    "        waveforms_train = np.array(f[\"raw_waveform\"])\n",
    "        ids_train = np.array(f[\"id\"])\n",
    "\n",
    "    print(f\"Loaded Train_{train_idx}: {len(waveforms_train)} waveforms\")\n",
    "\n",
    "    for i, wf in enumerate(waveforms_train):\n",
    "        if i % 5000 == 0:\n",
    "            print(f\"  Train_{train_idx} processing {i}/{len(waveforms_train)}\")\n",
    "\n",
    "        all_SCA_train.append(compute_spectral_centroid(wf))\n",
    "        all_train_ids_sca.append(f\"{ids_train[i]}_train_{train_idx}\")\n",
    "\n",
    "all_SCA_train = np.array(all_SCA_train, dtype=float)\n",
    "all_SCA_train[~np.isfinite(all_SCA_train)] = np.nan\n",
    "\n",
    "df_sca_train = pd.DataFrame({\n",
    "    \"id\": all_train_ids_sca,\n",
    "    \"SCA\": all_SCA_train\n",
    "})\n",
    "\n",
    "output_path_sca_train = os.path.join(OUTPUT_DIR, \"SCA_train_all.csv\")\n",
    "df_sca_train.to_csv(output_path_sca_train, index=False)\n",
    "\n",
    "print(\"\\nSaved combined SCA TRAIN CSV to:\", output_path_sca_train)\n",
    "print(df_sca_train.head())\n",
    "print(df_sca_train[\"SCA\"].describe())\n",
    "print(\"NaNs:\", df_sca_train[\"SCA\"].isna().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9476a440",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50bd4d03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0272fb58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Test_0: 65000 waveforms\n",
      "  Test_0 processing 0/65000\n",
      "  Test_0 processing 5000/65000\n",
      "  Test_0 processing 10000/65000\n",
      "  Test_0 processing 15000/65000\n",
      "  Test_0 processing 20000/65000\n",
      "  Test_0 processing 25000/65000\n",
      "  Test_0 processing 30000/65000\n",
      "  Test_0 processing 35000/65000\n",
      "  Test_0 processing 40000/65000\n",
      "  Test_0 processing 45000/65000\n",
      "  Test_0 processing 50000/65000\n",
      "  Test_0 processing 55000/65000\n",
      "  Test_0 processing 60000/65000\n",
      "Loaded Test_1: 65000 waveforms\n",
      "  Test_1 processing 0/65000\n",
      "  Test_1 processing 5000/65000\n",
      "  Test_1 processing 10000/65000\n",
      "  Test_1 processing 15000/65000\n",
      "  Test_1 processing 20000/65000\n",
      "  Test_1 processing 25000/65000\n",
      "  Test_1 processing 30000/65000\n",
      "  Test_1 processing 35000/65000\n",
      "  Test_1 processing 40000/65000\n",
      "  Test_1 processing 45000/65000\n",
      "  Test_1 processing 50000/65000\n",
      "  Test_1 processing 55000/65000\n",
      "  Test_1 processing 60000/65000\n",
      "Loaded Test_2: 65000 waveforms\n",
      "  Test_2 processing 0/65000\n",
      "  Test_2 processing 5000/65000\n",
      "  Test_2 processing 10000/65000\n",
      "  Test_2 processing 15000/65000\n",
      "  Test_2 processing 20000/65000\n",
      "  Test_2 processing 25000/65000\n",
      "  Test_2 processing 30000/65000\n",
      "  Test_2 processing 35000/65000\n",
      "  Test_2 processing 40000/65000\n",
      "  Test_2 processing 45000/65000\n",
      "  Test_2 processing 50000/65000\n",
      "  Test_2 processing 55000/65000\n",
      "  Test_2 processing 60000/65000\n",
      "Loaded Test_3: 65000 waveforms\n",
      "  Test_3 processing 0/65000\n",
      "  Test_3 processing 5000/65000\n",
      "  Test_3 processing 10000/65000\n",
      "  Test_3 processing 15000/65000\n",
      "  Test_3 processing 20000/65000\n",
      "  Test_3 processing 25000/65000\n",
      "  Test_3 processing 30000/65000\n",
      "  Test_3 processing 35000/65000\n",
      "  Test_3 processing 40000/65000\n",
      "  Test_3 processing 45000/65000\n",
      "  Test_3 processing 50000/65000\n",
      "  Test_3 processing 55000/65000\n",
      "  Test_3 processing 60000/65000\n",
      "Loaded Test_4: 65000 waveforms\n",
      "  Test_4 processing 0/65000\n",
      "  Test_4 processing 5000/65000\n",
      "  Test_4 processing 10000/65000\n",
      "  Test_4 processing 15000/65000\n",
      "  Test_4 processing 20000/65000\n",
      "  Test_4 processing 25000/65000\n",
      "  Test_4 processing 30000/65000\n",
      "  Test_4 processing 35000/65000\n",
      "  Test_4 processing 40000/65000\n",
      "  Test_4 processing 45000/65000\n",
      "  Test_4 processing 50000/65000\n",
      "  Test_4 processing 55000/65000\n",
      "  Test_4 processing 60000/65000\n",
      "Loaded Test_5: 65000 waveforms\n",
      "  Test_5 processing 0/65000\n",
      "  Test_5 processing 5000/65000\n",
      "  Test_5 processing 10000/65000\n",
      "  Test_5 processing 15000/65000\n",
      "  Test_5 processing 20000/65000\n",
      "  Test_5 processing 25000/65000\n",
      "  Test_5 processing 30000/65000\n",
      "  Test_5 processing 35000/65000\n",
      "  Test_5 processing 40000/65000\n",
      "  Test_5 processing 45000/65000\n",
      "  Test_5 processing 50000/65000\n",
      "  Test_5 processing 55000/65000\n",
      "  Test_5 processing 60000/65000\n",
      "\n",
      "Saved combined SCA TEST CSV to: finalcsveunice\\SCA_test_all.csv\n",
      "               id       SCA\n",
      "0  2395098_test_0  0.034359\n",
      "1  2395099_test_0  0.034267\n",
      "2  2395100_test_0  0.034659\n",
      "3  2395101_test_0  0.034947\n",
      "4  2395102_test_0  0.040895\n",
      "count    390000.000000\n",
      "mean          0.035721\n",
      "std           0.006291\n",
      "min           0.029060\n",
      "25%           0.034525\n",
      "50%           0.034808\n",
      "75%           0.035238\n",
      "max           0.192336\n",
      "Name: SCA, dtype: float64\n",
      "NaNs: 0\n"
     ]
    }
   ],
   "source": [
    "all_test_ids_sca = []\n",
    "all_SCA_test = []\n",
    "\n",
    "for test_idx in range(6):\n",
    "    test_file = f\"../data/old/MJD_Test_{test_idx}.hdf5\"\n",
    "    if not os.path.exists(test_file):\n",
    "        print(f\"Skipping missing file: {test_file}\")\n",
    "        continue\n",
    "\n",
    "    with h5py.File(test_file, \"r\") as f:\n",
    "        waveforms_test = np.array(f[\"raw_waveform\"])\n",
    "        ids_test = np.array(f[\"id\"])\n",
    "\n",
    "    print(f\"Loaded Test_{test_idx}: {len(waveforms_test)} waveforms\")\n",
    "\n",
    "    for i, wf in enumerate(waveforms_test):\n",
    "        if i % 5000 == 0:\n",
    "            print(f\"  Test_{test_idx} processing {i}/{len(waveforms_test)}\")\n",
    "\n",
    "        all_SCA_test.append(compute_spectral_centroid(wf))\n",
    "        all_test_ids_sca.append(f\"{ids_test[i]}_test_{test_idx}\")\n",
    "\n",
    "all_SCA_test = np.array(all_SCA_test, dtype=float)\n",
    "all_SCA_test[~np.isfinite(all_SCA_test)] = np.nan\n",
    "\n",
    "df_sca_test = pd.DataFrame({\n",
    "    \"id\": all_test_ids_sca,\n",
    "    \"SCA\": all_SCA_test\n",
    "})\n",
    "\n",
    "output_path_sca_test = os.path.join(OUTPUT_DIR, \"SCA_test_all.csv\")\n",
    "df_sca_test.to_csv(output_path_sca_test, index=False)\n",
    "\n",
    "print(\"\\nSaved combined SCA TEST CSV to:\", output_path_sca_test)\n",
    "print(df_sca_test.head())\n",
    "print(df_sca_test[\"SCA\"].describe())\n",
    "print(\"NaNs:\", df_sca_test[\"SCA\"].isna().sum())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
